///////////////////////////////////////////////////////////////////////////////
//
// Based on poly1305-x86_64.pl from OpenSSL 1.1.1-dev
// See https://github.com/openssl/openssl/blob/master/crypto/poly1305/asm/poly1305-x86_64.pl
// The original file contains the following notices:
//
// # ==================================================================== 
// # Copyright 2016 The OpenSSL Project Authors. All Rights Reserved.
// #
// # Licensed under the OpenSSL license (the "License").  You may not use
// # this file except in compliance with the License.  You can obtain a copy
// # in the file LICENSE in the source distribution or at
// # https://www.openssl.org/source/license.html
// #
// # ====================================================================
// # Written by Andy Polyakov <appro@openssl.org> for the OpenSSL
// # project. The module is, however, dual licensed under OpenSSL and
// # CRYPTOGAMS licenses depending on where you obtain it. For further
// # details see http://www.openssl.org/~appro/cryptogams/.
// # ==================================================================== 
//
///////////////////////////////////////////////////////////////////////////////

//include{:verbatim} "../../../../crypto/poly1305/x64/poly1305_math.i.dfy"
//include{:verbatim} "../../../../crypto/poly1305/x64/poly1305_util.i.dfy"
//include{:verbatim} "../../../../crypto/poly1305/x64/poly1305_bitvectors.i.dfy"
//include{:verbatim} "../../../../arch/x64/vale.i.dfy"
//include{:verbatim} "../../../../lib/util/operations.i.dfy"
//include "../../../../arch/x64/decls.vad"
//include "../../../../arch/x64/decls64.vad"
include "../../../../arch/x64/X64.Vale.Decls.vaf"

#verbatim interface implementation
module X64.Poly1305
#reset-options "--z3rlimit 20"
open X64.Machine_s
open X64.Vale.State_i
open X64.Vale.Decls
open X64.Vale.StrongPost_i
open Poly1305.Spec_s
open X64.Poly1305.Math_i
open Opaque_i
//open FStar.Tactics
#endverbatim

#verbatim interface

unfold let n = nat64_max

let validSrcAddrs64 (m:mem) (addr:int) (b:buffer64) (len:int) =
    //(buffer_readable m b \/ buffer_length b == 0) /\        // Buffer library's modifies clause treats 0-length buffers specially
    buffer_readable m b /\
    len <= buffer_length b /\
    buffer_addr b == addr

// TODO: This is dangerous, as it precludes changes to any other buffer    
let modifies_buffer_specific (b:buffer64) (h1 h2:mem) (start last:nat) : GTot Type0 =
    modifies_buffer b h1 h2 /\
    // TODO: Consider replacing this with: modifies (loc_buffer (gsub_buffer b i len)) h1 h2
    (forall (i:nat) . {:pattern (buffer64_read b i h2)}
                        0 <= i /\ i < buffer_length b 
                     /\ (i < start || i > last) 
                    ==> buffer64_read b i h1
                     == buffer64_read b i h2)

unfold let buffers_disjoint (b1 b2:buffer64) =
    locs_disjoint [loc_buffer b1; loc_buffer b2]

let readable_words (len:nat) =
    ((len + 15) / 16) `op_Multiply` 2 // 2 == 16 for rounding /8 for 8-byte words
#endverbatim


procedure poly1305_multiply(ghost r1:nat64) returns(ghost hh:int)
    lets
        d1 @= r8; d2 @= r9; d3 @= r10; r0 @= r11; s1 @= r13; h0 @= r14; h1 @= rbx; h2 @= rbp;
        n := nat64_max;
        p := n * n * 4 - 5;
        r := r1 * n + r0;
        h := h2 * (n * n) + h1 * n + h0;
    reads
        r11; r13;
    modifies
        r8; r9; r10; r14; rbx; rbp;
        rax; rdx;
        efl;
    requires
        r1 % 4 == 0;
        eq_int(s1, r1 + r1 /4);
        //s1 == r1 + r1 / 4;
        h2 * r0 < 7 * (n / 16);
        h0 * r1 < n * (n / 16);
        h1 * r0 < n * (n / 16);
        h2 * s1 < n * (n / 8);
        h0 * r0 < n * (n / 16);
        h1 * s1 < n * (n / 8);
        h2 * s1 < 7 * (5 * n / 64);
        rax == r1;
    ensures
        hh == (n * n) * d3 + n * h1 + h0;
        (h * r) % p == hh % p;
        d3 / 4 * 4 + d3 / 4 < 0x1_0000_0000_0000_0000;
        rax == 0xffff_ffff_ffff_fffc;
{
  // lemma_BitwiseAdd64();
   //lemma_BitwiseMul64();
    assert h0 * r1 == r1 * h0;
    assert r0 * h0 == h0 * r0;
    assert r0 * h1 == h1 * r0;
    //assert r0 * h2 == h2 * r0;
    assert s1 * h1 == h1 * s1;
    //assert s1 * h2 == h2 * s1;

    ghost var gd0 := h0 * r0 + h1 * s1;
    ghost var gd1 := h0 * r1 + h1 * r0 + h2 * s1;
    ghost var gd2 := h2 * r0;

    assert{:fast_block} true;
    Mul64Wrap(h0);  // h0*r1
    Mov64(d2, rax);
    Mov64(rax, r0);
    Mov64(d3, rdx);
    //assert n * d3 + d2 == old(h0 * r1);

    Mul64Wrap(h0);  // h0*r0
    Mov64(h0, rax); // future h0
    Mov64(rax, r0);
    Mov64(d1, rdx);
    //assert n * d1 + h0 == old(h0 * r0);

    Mul64Wrap(h1);  // h1*r0
    Add64Wrap(d2, rax);
    Mov64(rax, s1);
    Adc64Wrap(d3, rdx);
    //assert n * d3 + d2 == old(h0 * r1 + h1 * r0);

    Mul64Wrap(h1);  // h1*s1
    Mov64(h1, h2);  // borrow h1
    Add64Wrap(h0, rax);
    Adc64Wrap(d1, rdx);
    //assert n * d1 + h0 == old(h0 * r0 + h1 * s1);

    IMul64(h1, s1); // h2*s1
    Add64Wrap(d2, h1);
    Mov64(h1, d1);
    Adc64Wrap(d3, 0);
    //assert n * d3 + d2 == old(h0 * r1 + h1 * r0 + h2 * s1);

    IMul64(h2, r0); // h2*r0
    //assert h2 == gd2;
    Add64Wrap(h1, d2);
    Mov64(rax, 0xffff_ffff_ffff_fffc); // mask value
    Adc64Wrap(d3, h2);

    hh := (n * n) * d3 + n * h1 + h0;
    //assert hh == gd2 * (n * n) + gd1 * n + gd0;
    lemma_poly_multiply(n, p, r, h, r0, r1, old(h0), old(h1), old(h2), s1, gd0, gd1, gd2, hh);
}

procedure poly1305_reduce(
    inout dst_operand d3:uint64,
    inout dst_operand h0:uint64,
    inout dst_operand h1:uint64,
    inout dst_operand h2:uint64,
    ghost hd:int,
   //ghost n:int,
    ghost p:int)
    returns(ghost hh:int)
    modifies
        rax;
        efl;
    requires
        @d3 == OReg(R10);
        @h0 == OReg(R14);
        @h1 == OReg(Rbx);
        @h2 == OReg(Rbp);
    requires
        //n == 0x1_0000_0000_0000_0000;
        p == n * n * 4 - 5;
        hd == (n * n) * d3 + n * h1 + h0;
        d3 / 4 * 4 + d3 / 4 < 0x1_0000_0000_0000_0000;
        rax == 0xffff_ffff_ffff_fffc;
    ensures
        p > 0;  // TODO: Shouldn't need this!
        hh == (n * n) * h2 + n * h1 + h0;
        hd % p == hh % p;
        h2 < 5;
{
//    lemma_BitwiseAdd64();
    lemma_poly_bits64();

    And64(rax, d3);
    Mov64(h2, d3);
    Shr64(d3, 2);
    And64(h2, 3);
    Add64Wrap(rax, d3);
    Add64Wrap(h0, rax);
    Adc64Wrap(h1, 0);
    Adc64Wrap(h2, 0);

    ghost var h10 := n * old(h1) + old(h0);
    hh := h10 + rax + (old(d3) % 4) * (n * n);
    lemma_poly_reduce(n, p, hd, old(d3), h10, rax, hh);
}

procedure poly1305_reduce_regs(
    ghost hd:int,
    //ghost n:int,
    ghost p:int)
    returns(ghost hh:int)
    modifies
        rax;
        efl;
        r10;
        r14;
        rbx;
        rbp;
    requires
        //n == 0x1_0000_0000_0000_0000;
        p == n * n * 4 - 5;
        hd == (n * n) * r10 + n * rbx + r14;
        r10 / 4 * 4 + r10 / 4 < 0x1_0000_0000_0000_0000;
        rax == 0xffff_ffff_ffff_fffc;
    ensures
        p > 0;  // TODO: Shouldn't need this!
        hh == (n * n) * rbp + n * rbx + r14;
        hd % p == hh % p;
        rbp < 5;
{
//    lemma_BitwiseAdd64();
    lemma_poly_bits64();

    And64(rax, r10);
    Mov64(rbp, r10);
    Shr64(r10, 2);
    And64(rbp, 3);
    Add64Wrap(rax, r10);
    Add64Wrap(r14, rax);
    Adc64Wrap(rbx, 0);
    Adc64Wrap(rbp, 0);

    ghost var rbx0 := n * old(rbx) + old(r14);
    hh := rbx0 + rax + (old(r10) % 4) * (n * n);
    lemma_poly_reduce(n, p, hd, old(r10), rbx0, rax, hh);
}

procedure poly1305_reduce_regs_fast_block(
    ghost hd:int,
    //ghost n:int,
    ghost p:int)
    returns(ghost hh:int)
    modifies
        rax;
        efl;
        r10;
        r14;
        rbx;
        rbp;
    requires
        //n == 0x1_0000_0000_0000_0000;
        p == n * n * 4 - 5;
        hd == (n * n) * r10 + n * rbx + r14;
        r10 / 4 * 4 + r10 / 4 < 0x1_0000_0000_0000_0000;
        rax == 0xffff_ffff_ffff_fffc;
    ensures
        p > 0;  // TODO: Shouldn't need this!
        hh == (n * n) * rbp + n * rbx + r14;
        hd % p == hh % p;
        rbp < 5;
{
//    lemma_BitwiseAdd64();
    lemma_poly_bits64();

    assert{:fast_block} true;
    And64(rax, r10);
    Mov64(rbp, r10);
    Shr64(r10, 2);
    And64(rbp, 3);
    Add64Wrap(rax, r10);
    Add64Wrap(r14, rax);
    Adc64Wrap(rbx, 0);
    Adc64Wrap(rbp, 0);

    ghost var rbx0 := n * old(rbx) + old(r14);
    hh := rbx0 + rax + (old(r10) % 4) * (n * n);
    lemma_poly_reduce(n, p, hd, old(r10), rbx0, rax, hh);
}

procedure poly1305_iteration(
    inout dst_operand d1:uint64,
    inout dst_operand d2:uint64,
    inout dst_operand d3:uint64,
          operand r0:uint64,
          operand s1:uint64,
    inout dst_operand h0:uint64,
    inout dst_operand h1:uint64,
    inout dst_operand h2:uint64,
    ghost r1:nat64
    )
//    ghost r:int,
//    ghost h:int,
    //ghost n:int,
//    ghost p:int)
    returns(ghost hh:int)
    lets 
        p := n * n * 4 - 5;
        r := r1 * n + r0;
        h := h2 * (n * n) + h1 * n + h0;
    reads
        r11; r13;
    modifies
        r8; r9; r10; r14; rbx; rbp;
        rax; rdx;
        efl;
    requires
        @d1 == OReg(R8);
        @d2 == OReg(R9);
        @d3 == OReg(R10);
        @r0 == OReg(R11);
        @s1 == OReg(R13);
        @h0 == OReg(R14);
        @h1 == OReg(Rbx);
        @h2 == OReg(Rbp);
    requires
        //n == 0x1_0000_0000_0000_0000;
        r0 < n / 16;
        r1 < n / 16;
        r1 % 4 == 0;
        s1 == r1 + r1 / 4;
        h2 < 7;
        rax == r1;
    ensures
        p > 0;      // TODO: Shouldn't need this!
        hh == (n * n) * h2 + n * h1 + h0;
        modp(h * r) == modp(hh); 
        h2 < 5;
{
    // TODO: Delete me!
hh := 0;


//    Previous version used a forall statement, which isn't yet supported for F*
//    forall x:nat, xb, y:nat, yb :| x < xb && y < yb :: x * y < xb * yb
//    {
//        lemma_mul_strict_upper_bound(x, xb, y, yb);
//    }
    // TODO:  This version leads Z3 off into the weeds and times out with F* (but not Dafny)
    //assume forall x:nat, xb, y:nat, yb { x*y, xb*yb } :: x < xb && y < yb ==> x * y < xb * yb;

    lemma_mul_strict_upper_bound(h2, 7, r0, n / 16);
    lemma_mul_strict_upper_bound(h0, n, r1, n / 16);
    lemma_mul_strict_upper_bound(h1, n, r0, n / 16);
    lemma_mul_strict_upper_bound(h2, n, s1, n / 8);
    lemma_mul_strict_upper_bound(h0, n, r0, n / 16);
    lemma_mul_strict_upper_bound(h1, n, s1, n / 8);
    lemma_mul_strict_upper_bound(h2, 7, s1, 5 * n / 64);

    (ghost var hd) := poly1305_multiply(r1);
    hh := poly1305_reduce(d3, h0, h1, h2, hd, /* n, */ p);
    reveal_opaque(modp');
    assert hh == (n * n) * h2 + n * h1 + h0 && (h * r) % p == hh % p;
}

#verbatim
#reset-options "--z3rlimit 160"
#endverbatim

procedure {:frame false} poly1305_blocks(
//          operand ctx:uint64,
//    inout dst_operand inp:uint64,
//    inout dst_operand len:uint64,
//          operand padbit:uint64,
//    inout dst_operand d1:uint64,
//    inout dst_operand d2:uint64,
//    inout dst_operand d3:uint64,
//    inout dst_operand r0:uint64,
//    inout dst_operand r1:uint64,
//    inout dst_operand s1:uint64,
//    inout dst_operand h0:uint64,
//    inout dst_operand h1:uint64,
//    inout dst_operand h2:uint64,
    ghost r:int,
    ghost h_in:int,
    ghost ctx_b:buffer64,
    ghost inp_b:buffer64)
//    ghost ctx_id:heaplet_id,
//    ghost inp_id:heaplet_id)
    returns(ghost h:int)
    lets 
        ctx @= rdi; inp @= rsi; len @= rdx; padbit @= rcx; d1 @= r8; d2 @= r9; d3 @= r10;
        r0 @= r11; r1 @= r12; s1 @= r13; h0 @= r14; h1 @= rbx; h2 @= rbp;
        p := n * n * 4 - 5;
    requires/ensures
        ok;
    reads
        ctx; padbit; r11; r13;
    modifies
        inp; len; d1; d2; d3; r0; r1; s1; h0; h1; h2; 
        //r8; r9; r10; r14; rbx; rbp;
        rax; rdx; r15;
        efl;
        mem;
    requires
        //n == 0x1_0000_0000_0000_0000;
        // Len is measured in bytes
        len % 16 == 0; // REVIEW: may be stronger than necessary
        inp + len < nat64_max;
        //disjoint(ctx, 24*8, inp, len);
        buffers_disjoint(ctx_b, inp_b);
        validSrcAddrs64(mem, ctx, ctx_b, 24);
        validSrcAddrs64(mem, inp, inp_b, len / 8);
// TODO: Would be nice to have some syntax for buffer64_read
        let h0_in := buffer64_read(ctx_b, 0, mem);
        let h1_in := buffer64_read(ctx_b, 1, mem);
        let h2_in := buffer64_read(ctx_b, 2, mem);
        let r0_in := buffer64_read(ctx_b, 3, mem);
        let r1_in := buffer64_read(ctx_b, 4, mem);
        h_in == h2_in * (n * n) + h1_in * n + h0_in;
        r == r1_in * n + r0_in;
        r0_in < n / 16;
        r1_in < n / 16;
        r1_in % 4 == 0;
        h2_in < 5;
        padbit < 2;
    ensures
        h2 < 5;
        validSrcAddrs64(mem, ctx, ctx_b, 24);
        validSrcAddrs64(mem, old(inp), inp_b, old(len)/8);
        // Replaced the line below with memModified
        //mem == old(mem)[ctx_id := mem[ctx_id]];
        //memModified(old(mem), mem, old(ctx), 3 * 8);
        //modifies_buffer(ctx_b, old(mem), mem);
        modifies_buffer_specific(ctx_b, old(mem), mem, 0, 2);
        h0 == buffer64_read(ctx_b, 0, mem);
        h1 == buffer64_read(ctx_b, 1, mem);
        h2 == buffer64_read(ctx_b, 2, mem);
        r0 == buffer64_read(ctx_b, 3, mem);
        r1 == buffer64_read(ctx_b, 4, mem);
        s1 == r1 + r1 / 4;
        inp == old(inp + len);

        // Framing
        rcx == old(rcx);
        ctx == old(ctx); // REVIEW: framing should add this automatically

//        // TODO: The following is redundant with memModified above, and yet it seems to be necessary for poly_impl 
//        //       to go through, presumably because it uses more liberal triggers?
//        forall i :: 2 <= i < 24 ==> buffer64_read(ctx_b, i, mem) ==
//                                    buffer64_read(ctx_b, i, old(mem));
//        //forall i :: ctx + 24 <= i && i < ctx + 24 * 8 && (i - ctx) % 8 == 0 ==> mem[i] == old(mem)[i];
        let r0_in := buffer64_read(ctx_b, 3, mem);
        let r1_in := buffer64_read(ctx_b, 4, mem);
        h == h2 * (nat64_max * nat64_max) + h1 * nat64_max + h0;
        //(old(inp + len) - old(inp)) % 16 == 0; // TODO: Shouldn't need to repeat this
        //validSrcAddrs64(mem, old(inp), inp_b, old(len)); //forall j :: old(inp) <= j < old(inp + len) && (j - old(inp)) % 8 == 0 ==> in_mem(j, mem);
        modp(h) == poly1305_heap_blocks(modp(h_in), padbit * n * n, r, buffer64_as_seq(mem, inp_b), old(len) / 8); //old(inp), old(inp + len));

{
    h := 0;
    //lemma_BitwiseAdd64();
    lemma_poly_bits64();

    ghost var length := len;

//    assert {:fast_block} true;
    Shr64(len, 4);  // num_bytes / 16 ==> number of blocks
    // Slight difference: the original code has a special case for len == 0 here.
    // We can let len == 0 pass through because of the slight difference in the loop condition (see below)
    Mov64(r15, len); // reassign len

    Load64_buffer(r0, ctx, 24, ctx_b, 3); // load r
    Load64_buffer(s1, ctx, 32, ctx_b, 4);

    Load64_buffer(h0, ctx, 0, ctx_b, 0); // load hash value
    Load64_buffer(h1, ctx, 8, ctx_b, 1);
    Load64_buffer(h2, ctx, 16, ctx_b, 2);

    Mov64(r1, s1);
    Shr64(s1, 2);
    Mov64(rax, r1);
    Add64(s1, r1); // s1 = r1 + (r1 >> 2)

    h := h_in;
    assert modp(h) == poly1305_heap_blocks(modp(h_in), padbit * n * n, r, buffer64_as_seq(mem, inp_b), 0) by //, old(inp), inp) by
    {
        reveal_opaque(modp');
        reveal_poly1305_heap_blocks(modp(h_in), padbit * n * n, r, buffer64_as_seq(mem, inp_b), 0); //old(inp), inp);
    }

    ghost var word_index:int := 0;
    //assert r15 != 0 ==> 8*(word_index + 1) <= length;

    while (r15 != 0) // Slight difference: the original code uses the zero flag from "len-=16" rather than comparing len to 0
        invariant
            ok;
            n == 0x1_0000_0000_0000_0000;
            r == r1 * n + r0;
            h == h2 * (nat64_max * nat64_max) + h1 * nat64_max + h0;
            r0 < n / 16;
            r1 < n / 16;
            r1 % 4 == 0;
            s1 == r1 + r1 / 4;
            h2 < 5;
            rax == r1;
            inp + 16 * r15 == old(inp) + length;
            length == old(len);

            r15 != 0 ==> 8*(word_index + 1) <= length;
            16 * r15 + 8 * word_index == length;
            //2*r15 + 1 < length/8;
            inp + 0 /* offset */ == buffer_addr(inp_b) + 8 * word_index;

            r15 * 16 <= length;    // Not needed with Dafny version
            padbit < 2;            // Not needed with Dafny version 
            validSrcAddrs64(mem, ctx, ctx_b, 24);
            validSrcAddrs64(mem, old(inp), inp_b, length/8);
            ctx == old(ctx); // REVIEW: framing should add this automatically
            rcx == old(rcx); // REVIEW: framing should add this automatically
            //forall i :: ctx + 24 <= i < ctx + 24 * 8 && (i - ctx) % 8 == 0 ==> mem[i] == old(mem)[i];
            (inp - old(inp)) % 16 == 0;             // Precondition for poly1305_heap_blocks; Not needed in Dafny version
            //validSrcAddrs64(mem, old(inp), inp_b, inp - old(inp));  // Precondition for poly1305_heap_blocks; Not needed in Dafny version
//            0 <= (inp - old(inp))/16 <= old(len)/8;
//            (inp - old(inp))/16 % 2 == 0;
            modp(h) == poly1305_heap_blocks(modp(h_in), padbit * n * n, r, buffer64_as_seq(mem, inp_b), word_index); //(inp - old(inp))/16);
            //mem == old(mem)[ctx_id := mem[ctx_id]];
            //memModified(old(mem), mem, old(ctx), 3 * 8);
            mem == old(mem);
        decreases
            r15;
    {
        ghost var hp := h;
        ghost var old_mem := mem;
        h := h + n * n * padbit + n * buffer64_read(inp_b, word_index+1, mem) + buffer64_read(inp_b, word_index, mem);
        ghost var hq := h;

//        assert {:fast_block} true;
//        ghost var old_h0 := h0;
        Add64Wrap(h0, Mem(inp, 0, inp_b, word_index)); // accumulate input
        lemma_load_mem64(inp_b, word_index, mem);   // TODO: Really shouldn't need this, but it's the only connection between eval_operand and buffer64_read
//        assert h0 == add_wrap(old_h0, buffer64_read(inp_b, word_index, old_mem));
        Adc64Wrap(h1, Mem(inp, 8, inp_b, word_index+1));
        lemma_load_mem64(inp_b, word_index + 1, mem);   // TODO: Really shouldn't need this, but it's the only connection between eval_operand and buffer64_read
        AddLea64(inp, inp, 16);
        Adc64Wrap(h2, padbit);

        ghost var old_h := h2 * (n * n) + h1 * n + h0;
        assert old_h == hq;

        h := poly1305_iteration(d1, d2, d3, r0, s1, h0, h1, h2, r1);

        Mov64(rax, r1);
        Sub64(r15, 1); // len-=16
        word_index := word_index + 2;

        assert modp(h) == poly1305_heap_blocks(modp(h_in), padbit * n * n, r, buffer64_as_seq(mem, inp_b), word_index) by //(inp - old(inp))/16) by
        {
            reveal_poly1305_heap_blocks(modp(h_in), padbit * n * n, r, buffer64_as_seq(mem, inp_b), word_index); //(inp - old(inp))/16);
            reveal_poly1305_heap_blocks(modp(h_in), padbit * n * n, r, buffer64_as_seq(mem, inp_b), word_index - 2); //(inp - old(inp) - 16)/16);
            reveal_opaque(modp');
            lemma_poly_demod(p, hp, hq - hp, r);
//
//            assert h == (n * n) * h2 + n * h1 + h0;  // From poly1305_iteration
//            assert modp(h) == modp(old_h * r);       // From poly1305_iteration
//            assert modp(hp) == poly1305_heap_blocks(modp(h_in), padbit * n * n, r, old_mem, inp_b, word_index - 2);  // From loop invariant
//            
//            ghost var pad := padbit * n * n;
//            assert poly1305_heap_blocks(modp(h_in), pad, r, mem, inp_b, word_index) ==
//                   poly1305_heap_blocks'(modp(h_in), pad, r, mem, inp_b, word_index); // From reveal
//            // Unfolding poly1305_heap_blocks:
//            ghost var kk := word_index - 2;
//            ghost var hh := poly1305_heap_blocks'(modp(h_in), pad, r, mem, inp_b, kk);
//            assert poly1305_heap_blocks'(modp(h_in), pad, r, mem, inp_b, word_index) ==
////                   //modp((modp(hp) + padbit * n * n + nat64_max * mem[inp - 16 + 8] + mem[inp - 16]) * r);  // FAILS
////                   //modp((modp(hp) + old_h) * r);    // FAILS
////                   //modp((hh + padbit * n * n + nat64_max * mem[inp - 16 + 8] + mem[inp - 16]) * r);
//                   modp((hh + pad + nat64_max * buffer64_read(inp_b, kk + 1, mem)
//                                  + buffer64_read(inp_b, kk, mem)) * r);        // TRUE (with enough rlimit)
////            assert hh == modp(hp);
        }
    }
//    assert buffers_disjoint(ctx_b, inp_b);
    ghost var post_while_mem := mem;
    assert modp(h) == poly1305_heap_blocks(modp(h_in), padbit * n * n, r, buffer64_as_seq(mem, inp_b), old(len) / 8); 
//    assert 8 * word_index == length;
//    assert word_index == length / 8;
    assert validSrcAddrs64(mem, old(inp), inp_b, length/8);
    assert buffer_readable(mem, inp_b);

    // TODO: In theory, we shouldn't need this lemma any more
    //lemma_heap_blocks_preserved(mem, modp(h_in), padbit * n * n, r, ctx, 24*8, old(inp), inp);

    Store64_buffer(ctx, h0, 0, ctx_b, 0);

    //assert modifies_buffers(list(ctx_b), post_while_mem, mem);
    assert buffers_readable(mem, list(ctx_b));      // OBSERVE
    assert buffer_readable(mem, inp_b);

//    assert buffers_readable(mem, list(ctx_b));
//    assert buffer64_as_seq(post_while_mem, inp_b) == buffer64_as_seq(mem, inp_b);
    assert modp(h) == poly1305_heap_blocks(modp(h_in), padbit * n * n, r, buffer64_as_seq(mem, inp_b), old(len) / 8); 


    Store64_buffer(ctx, h1, 8, ctx_b, 1);
    assert buffers_readable(mem, list(ctx_b));      // OBSERVE
    Store64_buffer(ctx, h2, 16, ctx_b, 2);
    assert buffers_readable(mem, list(ctx_b));      // OBSERVE
    assert buffer_readable(mem, inp_b);
    assert validSrcAddrs64(mem, old(inp), inp_b, length/8);
}

#verbatim
#reset-options "--z3rlimit 200"
#endverbatim

// last 1..15 bytes, in case len is not a multiple of 16
procedure{:timeLimitMultiplier 2} poly1305_last_block(
    inout dst_operand h0:uint64,
    inout dst_operand h1:uint64,
    inout dst_operand h2:uint64,
          operand r0:uint64,
          operand s1:uint64,
          operand nExtra:uint64,
    ghost hBlocks:int,
    ghost r1:nat64,
    ghost r:int,
    ghost inpLast:nat128,
    //ghost n:int,
    ghost p:int)
    reads
        r11; r13;
    modifies
        r8; r9; r10; r14; rbx; rbp;
        rax; rcx; rdx; r9; 
        efl;
    requires
        @h0 == OReg(R14);
        @h1 == OReg(Rbx);
        @h2 == OReg(Rbp);
        @r0 == OReg(R11);
        @s1 == OReg(R13);
        @nExtra == OReg(R15);
    requires
        //n == 0x1_0000_0000_0000_0000;
        p == n * n * 4 - 5;
        h2 < 5;
        hBlocks == lowerUpper192_opaque(lowerUpper128_opaque(h0, h1), h2);
        r == lowerUpper128_opaque(r0, r1);
        rax == r1;
        r0 < n / 16;
        r1 < n / 16;
        r1 % 4 == 0;
        s1 == r1 + r1 / 4;
        inpLast == lowerUpper128_opaque(r8, r9);
        1 <= nExtra && nExtra < 16;
    ensures
        h2 < 5;
        let padLast := pow2(nExtra * 8);
        let hLast := lowerUpper192_opaque(lowerUpper128_opaque(h0, h1), h2);
        modp(hLast) == modp((modp(hBlocks) + padLast + (inpLast % padLast)) * r);
{
    ghost var padLast := pow2(nExtra * 8);
    //lemma_BitwiseAdd64();

    if (nExtra < 8) {
        lemma_bytes_shift_power2(nExtra);
        Mov64(rcx, nExtra);
        Shl64(rcx, 3);
        Mov64(rdx, 1);
        Shl64(rdx, rcx);
        assert rdx == padLast;

        // inpLast := (inpLast % padLast)
        lemma_bytes_and_mod(r8, nExtra);
        assert logand64(r8, shift_left64(1, shift_left64(nExtra, 3)) - 1) == r8 % shift_left64(1, shift_left64(nExtra, 3));
        assert padLast == shift_left64(1, shift_left64(nExtra, 3));
        lemma_mod_power2_lo(r8, r9, nExtra, pow2(nExtra * 8));
        Mov64(rcx, rdx);
        Sub64(rcx, 1);
        And64(r8, rcx);
        Mov64(r9, 0);
        assert r8 == old(r8) % padLast;
        assert lowerUpper128_opaque(r8, r9) == inpLast % padLast;

        // h += (inpLast % padLast)
        Add64Wrap(h0, r8);
        Adc64Wrap(h1, r9);
        Adc64Wrap(h2, 0);

        Add64Wrap(h0, rdx);
        Adc64Wrap(h1, 0);
        Adc64Wrap(h2, 0);
    } else {
        lemma_bytes_shift_power2(nExtra - 8);
        Mov64(rcx, nExtra);
        Sub64(rcx, 8);
        Shl64(rcx, 3);
        Mov64(rdx, 1);
        Shl64(rdx, rcx);

        //lemma_power2_add64(8 * nExtra - 64);
        //assert padLast == lowerUpper128_opaque(0, rdx);
        assert padLast == lowerUpper128_opaque(0, rdx) by {
            lemma_power2_add64(8 * nExtra - 64);
            reveal_opaque(lowerUpper128);
        }

        // inpLast := (inpLast % padLast)
        lemma_bytes_and_mod(r9, nExtra - 8);
        lemma_mod_hi(r8, r9, pow2(8 * (nExtra - 8)));
        Mov64(rcx, rdx);
        Sub64(rcx, 1);
        And64(r9, rcx);
        assert lowerUpper128_opaque(r8, r9) == inpLast % padLast;

        // h += (inpLast % padLast)
        Add64Wrap(h0, r8);
        Adc64Wrap(h1, r9);
        Adc64Wrap(h2, 0);

        Add64Wrap(h0, 0);
        Adc64Wrap(h1, rdx);
        Adc64Wrap(h2, 0);
    }

    ghost var h := hBlocks + (inpLast % padLast) + padLast;
    assert h == h2 * (n * n) + h1 * n + h0 by { reveal_opaque(lowerUpper192); reveal_opaque(lowerUpper128); }
    assert r == r1 * n + r0 by { reveal_opaque(lowerUpper128); }
    (ghost var hLast) := poly1305_iteration(r8, r9, r10, r0, s1, h0, h1, h2, r1);
    //assert modp(hLast) == modp(h * r);
//    //exists hLast :: (hLast == h2 * (n * n) + h1 * n + h0 && modp(h * r) == modp(hLast));
//
    assert hLast == lowerUpper192_opaque(lowerUpper128_opaque(h0, h1), h2) by { reveal_opaque(lowerUpper192); reveal_opaque(lowerUpper128); }
    lemma_poly_demod(p, hBlocks, (inpLast % padLast) + padLast, r);
//    ghost var x := (inpLast % padLast) + padLast;
//    assert modp((modp(hBlocks) + x) * r) == modp((hBlocks + x)*r) by { reveal_opaque(modp'); }
    assert modp(hLast) == modp((modp(hBlocks) + padLast + (inpLast % padLast)) * r) by { reveal_opaque(modp'); }
}

#verbatim
#reset-options "--z3rlimit 20"
#endverbatim

// h := (h % p) % 2^128;
procedure poly1305_reduce_last(
    inout dst_operand h0:uint64,
    inout dst_operand h1:uint64,
    inout operand h2:uint64,
    ghost h:int)
    modifies
        r8; r9; r10; rax;
        efl;
    requires
        @h0 == OReg(R14);
        @h1 == OReg(Rbx);
        @h2 == OReg(Rbp);
    requires
        h2 < 5;
        h == lowerUpper192_opaque(lowerUpper128_opaque(h0, h1), h2);
    ensures
        lowerUpper128_opaque(h0, h1) == mod2_128(modp(h));
{
//    lemma_BitwiseAdd64();
//    lemma_BitwiseSub64();
    lemma_poly_bits64();

    Mov64(r8, h0);
    Mov64(r9, h1);
    Mov64(r10, h2);
    Add64Wrap(r8, 5);
    Adc64Wrap(r9, 0);
    Adc64Wrap(r10, 0);

    assert h + 5 == lowerUpper192_opaque(lowerUpper128_opaque(r8, r9), r10)
        by { reveal_opaque(lowerUpper128); reveal_opaque(lowerUpper192); }
    lemma_reduce128(h, old(h2), old(h1), old(h0), h + 5, r10, r9, r8);

    Shr64(r10, 2);

    Mov64(rax, r10);
    Sub64Wrap(rax, 1); // mask of ones if h < p, zero otherwise
    //assert rax == (if r10 == 0 then 0xffff_ffff_ffff_ffff else 0);
    And64(h0, rax);
    And64(h1, rax);

    Mov64(rax, 0);
    Sub64Wrap(rax, r10); // mask of ones if p <= h < 2 * p, zero otherwise
    //assert rax == (if r10 == 1 then 0xffff_ffff_ffff_ffff else 0);
    And64(r8, rax);
    And64(r9, rax);

    // Either h1 == h0 == 0 or r9 == r8 == 0; add to select the nonzero one:
    Add64(h0, r8);
    Add64(h1, r9);
}

// h := (h + key_s) % 2^128
procedure poly1305_add_key_s(
    inout dst_operand h0:uint64,
    inout dst_operand h1:uint64,
          operand key_s0:uint64,
          operand key_s1:uint64,
    ghost h_in:int,
    ghost key_s:nat128)
    modifies
        efl;
    requires
        @h0 == OReg(R14);
        @h1 == OReg(Rbx);
        @key_s0 == OReg(Rax);
        @key_s1 == OReg(Rdx);
    requires
        h_in == lowerUpper128_opaque(h0, h1);
        key_s == lowerUpper128_opaque(key_s0, key_s1);
    ensures
        lowerUpper128_opaque(h0, h1) == mod2_128(h_in + key_s);
{
//    lemma_BitwiseAdd64();

    Add64Wrap(h0, key_s0);
    Adc64Wrap(h1, key_s1);

    lemma_add_key(old(h0), old(h1), h_in, key_s0, key_s1, key_s, h0, h1);

//    ghost var c := if cf(efl) then 0x1_0000_0000_0000_0000 * 0x1_0000_0000_0000_0000 else 0;
//    assert (h_in + key_s) % nat128_max == (c + lowerUpper128_opaque(h0, h1)) % nat128_max;
//    assert (c + lowerUpper128_opaque(h0, h1)) % nat128_max == lowerUpper128_opaque(h0, h1);
//    calc
//    {
//        mod2_128(h_in + key_s);              { reveal_opaque(lowerUpper128); }
//        mod2_128(c + lowerUpper128_opaque(h0, h1)); { reveal mod2_128; }
//        lowerUpper128_opaque(h0, h1);
//    }
}

#verbatim
(*
let retain_only (nss:list string) : tactic unit =
  prune "";; //removes every top-level assertion which has "" as a prefix; so prune everything
  addns "Prims" ;; //keep prims always
  _ig <-- mapM addns nss ;  //add back only things in nss
  return ()

let retain_only_modp () = 
    retain_only ["Opaque_i"; "X64.Poly1305.Spec_s"; "X64.Poly1305"; "X64.Poly1305.Math_i"] //; "FStar.Seq"]`
*)

let modp_0 () : Lemma
  (requires True)
  (ensures modp 0 == 0)
    =
    reveal_opaque modp';
    ()
let bare_r (key_r:nat128) = FStar.UInt.logand #128 key_r 0x0ffffffc0ffffffc0ffffffc0fffffff 

#reset-options "--z3rlimit 200"

#endverbatim

// TODO: Procedure was consistently sending Z3 into the woods when frame was true
procedure {:frame false} poly1305_impl(
//          reg_operand ctx:uint64,
    ghost key_r:nat128,
    ghost key_s:nat128,
    ghost ctx_b:buffer64,
    ghost inp_b:buffer64)
//    ghost ctx_id:heaplet_id,
//    ghost inp_id:heaplet_id)
    returns(ghost h:int)
    lets
        ctx @= rdi; inp @= rsi; len @= rdx; r0 @= r11; r1 @= r12; h0 @= r14; h1 @= rbx; h2 @= rbp;
        n := nat64_max;
        p := n * n * 4 - 5;
    requires/ensures
        ok;
    modifies
        rax; rcx; rdx; r8; r9; r10; r13; r15;
        rdi; rsi; rdx; r11; r12; r14; rbx; rbp;
        efl;
        mem;
    requires
        //disjoint(ctx, 24*8, inp, (len + 15) / 16 * 16);
        buffers_disjoint(ctx_b, inp_b);
        validSrcAddrs64(mem, ctx, ctx_b, 24);
        validSrcAddrs64(mem, inp, inp_b, readable_words(len));
        inp + len < nat64_max;
        let key_r0 := buffer64_read(ctx_b, 3, mem);
        let key_r1 := buffer64_read(ctx_b, 4, mem);
        let key_s0 := buffer64_read(ctx_b, 5, mem);
        let key_s1 := buffer64_read(ctx_b, 6, mem);
        key_r == lowerUpper128_opaque(key_r0, key_r1);
        key_s == lowerUpper128_opaque(key_s0, key_s1);
    ensures
//        ctx == old(ctx);
        validSrcAddrs64(mem, ctx, ctx_b, 24);
        validSrcAddrs64(mem, old(inp), inp_b, readable_words(old(len)));
//        // Replaced line below with memModified
//        //mem == old(mem)[ctx_id := mem[ctx_id]];
        //memModified(old(mem), mem, old(ctx), 9 * 8);

        // TODO: This is implied by the specific version
        modifies_buffer(ctx_b, old(mem), mem);
        modifies_buffer_specific(ctx_b, old(mem), mem, 0, 8);
//        forall i :: 9 <= i < 24 ==> buffer64_read(ctx_b, i, mem) == 
//                                    buffer64_read(ctx_b, i, old(mem));

        h == lowerUpper128_opaque(h0, h1);
        let inp_mem := heapletTo128(buffer64_as_seq(mem, inp_b), readable_words(old(len))); //old(len));
//        // TODO: Figure out why there's an internal Vale error on the inp_mem?[j] invocation
//        //forall j :: old(inp) <= j < old(inp) + old(len) && (j - old(inp)) % 16 == 0 ==> inp_mem?[j];
//        forall i :: ctx + 72 <= i && i < ctx + 24 * 8 && (i - ctx) % 8 == 0 ==> mem[i] == old(mem)[i];
        h == poly1305_hash(key_r, key_s, inp_mem, old(len));
//        // Framing
//        rbx == old(rbx);
//        rsi == old(rsi);
        ctx == old(ctx);
//        rbp == old(rbp);
//        rsp == old(rsp);
//        r11 == old(r11);
//        r12 == old(r12);
//        r14 == old(r14);
{
    ghost var inp_in := inp;
    ghost var len_in := len;
    ghost var key_r0 := buffer64_read(ctx_b, 3, mem);
    ghost var key_r1 := buffer64_read(ctx_b, 4, mem);
    lemma_poly_bits64();
    //lemma_BitwiseAdd64();

    //assert{:fast_block} true;
    Mov64(rax, 0);
    Store64_buffer(ctx, rax,  0, ctx_b, 0);
    Store64_buffer(ctx, rax,  8, ctx_b, 1);
    Store64_buffer(ctx, rax, 16, ctx_b, 2);

    Load64_buffer(r0, ctx, 24, ctx_b, 3);
    Load64_buffer(r1, ctx, 32, ctx_b, 4);
    Mov64(rcx, 0x0fff_fffc_0fff_ffff);
    And64(r0, rcx);
    Mov64(rcx, 0x0fff_fffc_0fff_fffc);
    And64(r1, rcx);
    Store64_buffer(ctx, r0, 24, ctx_b, 3);
    Store64_buffer(ctx, r1, 32, ctx_b, 4);

    ghost var r:nat128 := lowerUpper128_opaque(r0, r1);
    assert r == r0 + n * r1 by { reveal_opaque(lowerUpper128); }

    assert r == logand128(key_r, 0x0ffffffc_0ffffffc_0ffffffc_0fffffff) by
    {
        reveal_opaque(lowerUpper128);
        lemma_lowerUpper128_and(key_r, key_r0, key_r1, 0x0ffffffc_0ffffffc_0ffffffc_0fffffff,
            0x0fff_fffc_0fff_ffff, 0x0fff_fffc_0fff_fffc, r, r0, r1);
    }

assume false;       // Everything slows down here.  Fix with fast_block?
    //assert{:fast_block} true;
    Mov64(rax, len);
    And64(rax, 15);
    Sub64(len, rax);
    // assert rax == len_in % 16;
    // assert len == len_in / 16 * 16; == (num 16-byte blocks) * 16
    Store64_buffer(ctx, rax, 56, ctx_b, 7);
    Store64_buffer(ctx, len, 64, ctx_b, 8);

    Mov64(rcx, 1);
    h := poly1305_blocks(r, 0, ctx_b, inp_b);
    assert modp(0) == 0 by
    {
        modp_0();
//        reveal_opaque(modp');
//        assert_by_tactic(modp(0) == 0, retain_only_modp());
    }

    lemma_poly1305_heap_hash_blocks(0, n * n, r, mem, inp_b, inp_in + len_in / 16 * 16, len_in);

    reveal_logand128(key_r, 0x0ffffffc0ffffffc0ffffffc0fffffff);
    assert r == bare_r(key_r);
    assert h == lowerUpper192_opaque(lowerUpper128_opaque(h0, h1), h2)
        by { reveal_opaque(lowerUpper192); reveal_opaque(lowerUpper128); }

    Load64_buffer(r15, ctx, 56, ctx_b, 7); 
    assert r15 == len_in % 16;        
    if (r15 != 0)
    {
        //assert{:fast_block} true;
        Load64_buffer(rax, ctx, 32, ctx_b, 4);
        Load64_buffer(r8, inp, 0, inp_b, 0);
        Load64_buffer(r9, inp, 8, inp_b, 1);
        ghost var a := applyHeapletTo128(buffer64_as_seq(mem, inp_b), (len + 15) / 16 * 16, inp);
        assert lowerUpper128_opaque(r8, r9) == a
            by { /* reveal heapletTo128; */ reveal_opaque(lowerUpper128); }
        poly1305_last_block(h0, h1, h2, r0, r13, r15, h, r1, r, lowerUpper128_opaque(r8, r9), /*n,*/ p);
        h := lowerUpper192_opaque(lowerUpper128_opaque(h0, h1), h2);
    }

    lemma_add_mod128(modp(h), key_s);
    poly1305_reduce_last(h0, h1, h2, h);
    h := lowerUpper128_opaque(h0, h1);

    Load64_buffer(rax, ctx, 40, ctx_b, 5);
    Load64_buffer(rdx, ctx, 48, ctx_b, 6);
    poly1305_add_key_s(h0, h1, rax, rdx, h, key_s);
    h := lowerUpper128_opaque(h0, h1);

    assert h == poly1305_hash(key_r, key_s, heapletTo128(buffer64_as_seq(mem, inp_b), len_in), len_in)
        by { reveal_opaque(mod2_128'); reveal_opaque(modp'); }
}

#verbatim
#reset-options "--z3rlimit 200" 
#endverbatim

// poly1305(ctx, inp, len)
//
// Note that this reads 16-byte chunks directly from the input buffer,
// so (len + 15) / 16 * 16 bytes must be readable, even though only len bytes
// affect the result.
procedure {:frame false} poly1305(
    inline win:bool,
    ghost key_r:nat128,
    ghost key_s:nat128,
    //ghost n:int,
    ghost p:int,
    ghost ctx_in:nat64,
    ghost inp_in:nat64,
    ghost len_in:nat64,
    ghost ctx_b:buffer64,
    ghost inp_b:buffer64)
    returns(ghost h:int)
    lets ctx @= rdi; inp @= rsi; len @= rdx; r0 @= r11; r1 @= r12; h0 @= r14; h1 @= rbx; h2 @= rbp;
    requires/ensures
        ok;
    modifies
        rax; rcx; rdx; r8; r9; r10; r13; r15;
        rdi; rsi; rbx; rbp; r12; r14;
        efl;
        mem;
    requires
        ctx_in == (if win then rcx else ctx);
        inp_in == (if win then rdx else inp);
        len_in == (if win then r8 else len);
        //n == 0x1_0000_0000_0000_0000;
        p == n * n * 4 - 5;
        //disjoint(ctx_in, 24*8, inp_in, (len_in + 15) / 16 * 16);
        buffers_disjoint(ctx_b, inp_b);
        validSrcAddrs64(mem, ctx_in, ctx_b, 24);
        validSrcAddrs64(mem, inp_in, inp_b, readable_words(len_in));
        inp_in + len_in < nat64_max;
        let key_r0 := buffer64_read(ctx_b, 3, mem);
        let key_r1 := buffer64_read(ctx_b, 4, mem);
        let key_s0 := buffer64_read(ctx_b, 5, mem);
        let key_s1 := buffer64_read(ctx_b, 6, mem);
        key_r == lowerUpper128_opaque(key_r0, key_r1);
        key_s == lowerUpper128_opaque(key_s0, key_s1);
    ensures
        validSrcAddrs64(mem, ctx_in, ctx_b, 24);
        validSrcAddrs64(mem, inp_in, inp_b, readable_words(len_in));
//        // Replaced line below with memModified
//        //mem == old(mem)[ctx_id := mem[ctx_id]];
        //memModified(old(mem), mem, ctx_in, 24 * 8);
        modifies_buffer(ctx_b, old(mem), mem);
        let h0_out := buffer64_read(ctx_b, 0, mem);
        let h1_out := buffer64_read(ctx_b, 1, mem);
        h == lowerUpper128_opaque(h0_out, h1_out);
        let inp_mem := heapletTo128(buffer64_as_seq(mem, inp_b), readable_words(len_in));
        h == poly1305_hash(key_r, key_s, inp_mem, len_in);
        h1 == old(h1);
        h2 == old(h2);
        ctx == old(ctx);
        inp == old(inp);
        r1 == old(r1);
        r13 == old(r13);
        h0 == old(h0);
        r15 == old(r15);
{
    h := 0; 
    Mov64(rax, ctx);
    Mov64(r9, inp);
    inline if (win)
    {
        Mov64(ctx, rcx);
        Mov64(inp, rdx);
        Mov64(len, r8);
    }
    // assert ctx == ctx_in;
    // assert inp == inp_in;
    // assert len == len_in;

    // context:
    //   0, 8, 16: will hold h
    //   24, 32: key_r
    //   40, 48: key_s
    //   56: will hold len % 16
    //   64: will hold len / 16 * 16
    //   72, 80, 88, 96, 104, 112, 120, 128: callee-save registers
    //assert {:fast_block} true;

//    assert validSrcAddrs64(mem, inp, inp_b, readable_words(len));
//    assert buffers_disjoint(ctx_b, inp_b);
//    assert locs_disjoint(list(loc_buffer(ctx_b), loc_buffer(inp_b)));
//    assert buffer_readable(mem, inp_b);
    ghost var old_h1 := h1;                         // OBSERVE
    ghost var old_h2 := h2;                         // OBSERVE
    assert old_h1 == old(h1);                       // OBSERVE
    assert old_h2 == old(h2);                       // OBSERVE
    Store64_buffer(ctx, h1,  72, ctx_b, 9);
    assert buffers_readable(mem, list(ctx_b));      // OBSERVE
    assert buffer64_read(ctx_b, 9, mem) == old_h1;  // OBSERVE
//    assert validSrcAddrs64(mem, inp, inp_b, readable_words(len));

//    assert buffer_readable(mem, inp_b);
//    assert readable_words(len) == buffer_length(inp_b);
//    assert buffer_addr(inp_b) == inp; 
//
//    assert validSrcAddrs64(mem, inp, inp_b, readable_words(len));
    Store64_buffer(ctx, h2,  80, ctx_b, 10);
    assert buffer64_read(ctx_b, 9, mem) == old_h1;  // OBSERVE
    assert buffer64_read(ctx_b, 10, mem) == old_h2; // OBSERVE
    assert buffers_readable(mem, list(ctx_b));      // OBSERVE
    Store64_buffer(ctx, rax, 88, ctx_b, 11);
    assert buffer64_read(ctx_b, 10, mem) == old_h2; // OBSERVE
    assert buffers_readable(mem, list(ctx_b));      // OBSERVE
    Store64_buffer(ctx, r9,  96, ctx_b, 12);
    assert buffers_readable(mem, list(ctx_b));      // OBSERVE
    Store64_buffer(ctx, r1,  104, ctx_b, 13);
    assert buffers_readable(mem, list(ctx_b));      // OBSERVE
    Store64_buffer(ctx, r13, 112, ctx_b, 14);
    assert buffers_readable(mem, list(ctx_b));      // OBSERVE
    Store64_buffer(ctx, h0,  120, ctx_b, 15);
    assert buffers_readable(mem, list(ctx_b));      // OBSERVE
    Store64_buffer(ctx, r15, 128, ctx_b, 16);
    assert buffers_readable(mem, list(ctx_b));      // OBSERVE
//    assert validSrcAddrs64(mem, inp, inp_b, readable_words(len));

    ghost var old_inp := rsi;
    ghost var old_len := rdx;
    h := poly1305_impl(key_r, key_s, ctx_b, inp_b);
    assert buffer64_read(ctx_b, 9, mem) == old_h1;  // OBSERVE
    assert buffer64_read(ctx_b, 10, mem) == old_h2; // OBSERVE

    // TODO: In theory, no longer needed
    //heapletTo128_all_preserved(mem, ctx, 9 * 8, old_inp, old_len);  // Hold onto facts about heapletTo128(mem, old_inp, old_len);

    //assert {:fast_block} true;
    assert buffers_readable(mem, list(ctx_b));      // OBSERVE
    Store64_buffer(ctx, h0,  0, ctx_b, 0);
    assert buffers_readable(mem, list(ctx_b));      // OBSERVE
    Store64_buffer(ctx, h1,  8, ctx_b, 1);
    assert buffers_readable(mem, list(ctx_b));      // OBSERVE

    Load64_buffer(h1,  ctx, 72, ctx_b, 9);
    assert buffer64_read(ctx_b, 9, mem) == old_h1;  // OBSERVE
    Load64_buffer(h2,  ctx, 80, ctx_b, 10);
    Load64_buffer(rax, ctx, 88, ctx_b, 11);
    Load64_buffer(inp, ctx, 96, ctx_b, 12);
    Load64_buffer(r1,  ctx, 104, ctx_b, 13);
    Load64_buffer(r13, ctx, 112, ctx_b, 14);
    Load64_buffer(h0,  ctx, 120, ctx_b, 15);
    Load64_buffer(r15, ctx, 128, ctx_b, 16);
    Mov64(ctx, rax);
    assert buffer64_read(ctx_b, 9, mem) == old_h1;  // OBSERVE
    assert buffer64_read(ctx_b, 10, mem) == old_h2; // OBSERVE


// TODO: Remove these once we solve triggering issues above
    assume ctx == old(ctx);
    assume inp == old(inp);
    assume r1 == old(r1);
    assume r13 == old(r13);
    assume h0 == old(h0);
    assume r15 == old(r15);
}
