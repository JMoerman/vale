#verbatim interface
module X64.Vale.Decls
module M = Memory_i_s

// This interface should hide all of Semantics_s.
// (It should not refer to Semantics_s, directly or indirectly.)
// It should not refer to StateLemmas_i, Lemmas_i, or Print_s,
// because they refer to Semantics_s.
// Regs_i and State_i are ok, because they do not refer to Semantics_s.

open X64.Machine_s
open X64.Vale.State_i

val cf : (flags:int) -> bool

//unfold let va_subscript = Map.sel
unfold let va_subscript (#a:eqtype) (#b:Type) (x:Map.t a b) (y:a) : Tot b = Map.sel x y
unfold let va_update = Map.upd
unfold let va_make_opaque = Opaque_i.make_opaque
unfold let va_reveal_opaque = Opaque_i.reveal_opaque
unfold let va_hd = Cons?.hd
unfold let va_tl = Cons?.tl
unfold let va_normalize_term = normalize_term

(* Type aliases *)
unfold let va_bool = bool
unfold let va_int = int
val ins : Type0
val ocmp : Type0
unfold let va_code = precode ins ocmp
unfold let va_codes = list va_code
unfold let va_state = state
val va_fuel : Type0
unfold let va_operand = operand
let va_reg_operand = o:operand{OReg? o}
let va_src_operand = o:operand{OReg? o \/ OConst? o}
let va_dst_operand = o:dst_op{OReg? o \/ OConst? o}
let va_shift_amt = o:operand{OReg? o \/ OConst? o}
let va_cmp = o:operand{OReg? o \/ OConst? o}
let va_taint = taint
unfold let va_register = reg

(* Abbreviations *)
unfold let get_reg (o:va_reg_operand) : reg = OReg?.r o
//unfold let buffer_readable = M.buffer_readable
unfold let buffer_readable (#t:M.typ) (h:mem) (b:M.buffer t) = M.buffer_readable #t h b
//unfold let buffer_length = M.buffer_length
unfold let buffer_length (#t:M.typ) (b:M.buffer t) = M.buffer_length #t b
unfold let buffer64_as_seq (m:mem) (b:buffer64) : GTot (Seq.seq nat64) = M.buffer_as_seq m b
unfold let valid_src_addr (m:mem) (b:buffer64) (i:int) : Type0 =
  0 <= i /\ i < buffer_length b /\ buffer_readable m b
unfold let valid_dst_addr (m:mem) (b:buffer64) (i:int) : Type0 =
  0 <= i /\ i < buffer_length b /\ buffer_readable m b
unfold let buffer64_read (b:buffer64) (i:int) (m:mem) : nat64 = M.buffer_read b i m
unfold let buffer64_write (b:buffer64) (i:int) (v:nat64) (m:mem) : mem = M.buffer_write b i v m
unfold let modifies_mem (s:M.loc) (h1 h2:mem) : GTot Type0 = M.modifies s h1 h2
//unfold let loc_buffer = M.loc_buffer
unfold let loc_buffer(#t:M.typ) (b:M.buffer t) = M.loc_buffer #t b
unfold let locs_disjoint = M.locs_disjoint
let modifies_memTaint (a:int) (m1 m2: map int taint) : GTot Type0 =
    m2 == Map.upd m1 a Public \/ m2 == Map.upd m1 a Secret

(* Constructors *)
val va_fuel_default : unit -> va_fuel
unfold let va_op_operand_reg (r:reg) : va_operand = OReg r
unfold let va_op_src_operand_reg (r:reg) : va_src_operand = OReg r
unfold let va_const_operand (n:int) = OConst n
unfold let va_const_src_operand (n:int) = OConst n
unfold let va_const_shift_amt (n:int) : va_shift_amt = OConst n
unfold let va_op_shift_amt_reg(r:reg) : va_shift_amt = OReg r
unfold let va_op_cmp_reg (r:reg) : va_cmp = OReg r
unfold let va_const_cmp (n:int) : va_cmp = OConst n
unfold let va_coerce_register_to_operand (r:va_register) : va_operand = OReg r
unfold let va_coerce_operand_to_reg_operand (o:va_operand{OReg? o}) : va_reg_operand = o
unfold let va_coerce_operand_to_src_operand (o:va_operand{OReg? o \/ OConst? o}) : va_src_operand = o
unfold let va_coerce_dst_operand_to_reg_operand (o:va_dst_operand{OReg? o}) : va_reg_operand = o
unfold let va_coerce_operand_to_cmp(o:va_operand{OReg? o \/ OConst? o}) : va_cmp = o
unfold let va_coerce_src_operand_to_cmp (o:va_src_operand) : va_cmp = o
unfold let va_op_register (r:reg) : va_register = r
unfold let va_op_reg_operand_reg (r:reg) : va_reg_operand = OReg r
unfold let va_op_dst_operand_reg (r:reg{not (Rsp? r)}) : va_dst_operand = OReg r
unfold let va_coerce_operand_to_dst_operand (o:va_operand{valid_dst o /\ (OConst? o \/ OReg? o)}) : va_dst_operand = o
unfold let va_coerce_dst_operand_to_operand (o:va_dst_operand) : va_operand = o
unfold let va_coerce_dst_operand_to_src_operand (o:va_dst_operand) : va_src_operand = o
unfold let va_opr_code_Mem (o:operand) (offset:int) : operand =
  match o with
  | OConst n -> OConst (n + offset)
  | OReg r -> OMem (MReg r offset)
  | _ -> OConst 42

unfold let va_opr_lemma_Mem (s:va_state) (base:operand{OReg? base})//:operand{valid_operand base s}) 
       	   		    (t:taint)
       	   		    (offset:int{s.memTaint.[eval_operand base s + offset] == t}) // Need this if we want to handle OConst as base values: { 0 <= (eval_operand base s) + offset && (eval_operand base s) + offset < nat64_max }) 
                            (b:buffer64) 
                            (index:int{valid_src_addr s.mem b index /\ 
                                       (eval_operand base s) + offset == buffer_addr(b) + 8 `op_Multiply` index}) 
                            : (o:operand{valid_operand o s /\ valid_taint o s t}) =
  lemma_valid_mem64 b index s.mem;
  va_opr_code_Mem base offset
(*
function method va_opr_lemma_Mem(s:va_state, base:va_operand, offset:int, taint:taint, id:heaplet_id):va_mem_operand
    requires x86_ValidState(s)
    requires base.OReg?
    requires ValidMemAddr(MReg(base.r, offset))
    requires ValidSrcAddr(s.heaplets, id, va_get_reg64(base.r, s) + offset, 64, taint)
    ensures  Valid64BitSourceOperand(to_state(s), OHeap(MReg(base.r, offset), taint))
    ensures  eval_op64(to_state(s), OHeap(MReg(base.r, offset), taint)) == s.heaplets[id].mem64[va_get_reg64(base.r, s) + offset].v
{
    reveal_x86_ValidState();
    va_opr_code_Mem(base, offset, taint)
}
*)


(* Evaluation *)
unfold let va_eval_operand_uint64     (s:va_state) (o:va_operand)     : nat64 = eval_operand o s
unfold let va_eval_src_operand_uint64 (s:va_state) (o:va_src_operand) : nat64 = eval_operand o s
unfold let va_eval_dst_operand_uint64 (s:va_state) (o:va_dst_operand) : nat64 = eval_operand o s
unfold let va_eval_shift_amt_uint64   (s:va_state) (o:va_shift_amt)   : nat64 = eval_operand o s
unfold let va_eval_cmp_uint64         (s:va_state) (r:va_cmp)         : nat64 = eval_operand r s
unfold let va_eval_register_uint64    (s:va_state) (r:va_register)    : nat64 = eval_reg r s
unfold let va_eval_reg_operand_uint64 (s:va_state) (o:va_reg_operand) : nat64 = eval_reg (OReg?.r o) s

(* Predicates *)
unfold let va_is_src_operand_uint64 (o:operand) (s:va_state) = valid_operand o s
let va_is_src_src_operand_uint64 (o:operand) (s:va_state) = valid_operand o s /\ (OReg? o || OConst? o)
let va_is_dst_operand_uint64 (o:operand) (s:va_state) = OReg? o && not (Rsp? (OReg?.r o))
let va_is_dst_dst_operand_uint64 (o:va_dst_operand) (s:va_state) = OReg? o && not (Rsp? (OReg?.r o))
let va_is_dst_src_operand_uint64 (o:va_src_operand) (s:va_state) = OReg? o && not (Rsp? (OReg?.r o))
unfold let va_is_src_register_int (r:reg) (s:va_state) = True
unfold let va_is_dst_register (r:reg) (s:va_state) = True
unfold let va_is_src_shift_amt_uint64 (o:operand) (s:va_state) = (OConst? o || OReg? o) /\ valid_operand o s /\ (va_eval_shift_amt_uint64 s o) < 64
unfold let va_is_src_reg_operand_uint64 (o:operand) (s:va_state) = OReg? o

(* Getters *)
unfold let va_get_ok (s:va_state) : bool = s.ok
unfold let va_get_flags (s:va_state) : int = s.flags
unfold let va_get_reg (r:reg) (s:va_state) : nat64 = eval_reg r s
unfold let va_get_mem (s:va_state) : mem = s.mem
unfold let va_get_trace (s:va_state) : list observation = s.trace
unfold let va_get_memTaint (s:va_state) : map int taint = s.memTaint

(* Framing: va_update_foo means the two states are the same except for foo *)
unfold let va_update_ok (sM:va_state) (sK:va_state) : va_state = { sK with ok = sM.ok }
unfold let va_update_flags (sM:va_state) (sK:va_state) : va_state = { sK with flags = sM.flags }

unfold
let va_update_reg (r:reg) (sM:va_state) (sK:va_state) : va_state =
  update_reg r (eval_reg r sM) sK

unfold let va_update_mem (sM:va_state) (sK:va_state) : va_state = { sK with mem = sM.mem }

let va_update_operand (o:operand) (sM:va_state) (sK:va_state) : va_state =
  match o with
  | OConst n -> sK
  | OReg r -> va_update_reg r sM sK
  | OMem m -> va_update_mem sM sK 

unfold
let va_update_dst_operand (o:dst_op) (sM:va_state) (sK:va_state) : va_state =
  va_update_operand o sM sK   

unfold
let va_update_src_operand (o:va_src_operand) (sM:va_state) (sK:va_state) : va_state =
  va_update_operand o sM sK

unfold
let va_update_register (r:reg) (sM:va_state) (sK:va_state) : va_state =
  va_update_reg r sM sK

unfold let va_update_trace (sM:va_state) (sK:va_state) : va_state = { sK with trace = sM.trace }
unfold let va_update_memTaint (sM:va_state) (sK:va_state) : va_state = { sK with memTaint = sM.memTaint }

(** Constructors for va_codes *)
unfold let va_CNil () : va_codes = []
unfold let va_CCons (hd:va_code) (tl:va_codes) : va_codes = hd::tl

(** Constructors for va_code *)
unfold let va_Block (block:va_codes) : va_code = Block block
unfold let va_IfElse (ifCond:ocmp) (ifTrue:va_code) (ifFalse:va_code) : va_code = IfElse ifCond ifTrue ifFalse
unfold let va_While (whileCond:ocmp) (whileBody:va_code) : va_code = While whileCond whileBody

val va_cmp_eq (o1:va_src_operand) (o2:va_src_operand) : ocmp
val va_cmp_ne (o1:va_src_operand) (o2:va_src_operand) : ocmp
val va_cmp_le (o1:va_src_operand) (o2:va_src_operand) : ocmp
val va_cmp_ge (o1:va_src_operand) (o2:va_src_operand) : ocmp
val va_cmp_lt (o1:va_src_operand) (o2:va_src_operand) : ocmp
val va_cmp_gt (o1:va_src_operand) (o2:va_src_operand) : ocmp

unfold let va_get_block (c:va_code{Block? c}) : va_codes = Block?.block c
unfold let va_get_ifCond (c:va_code{IfElse? c}) : ocmp = IfElse?.ifCond c
unfold let va_get_ifTrue (c:va_code{IfElse? c}) : va_code = IfElse?.ifTrue c
unfold let va_get_ifFalse (c:va_code{IfElse? c}) : va_code = IfElse?.ifFalse c
unfold let va_get_whileCond (c:va_code{While? c}) : ocmp = While?.whileCond c
unfold let va_get_whileBody (c:va_code{While? c}) : va_code = While?.whileBody c

(** Map syntax **)
// syntax for map accesses, m.[key] and m.[key] <- value 
type map (key:eqtype) (value:Type) = Map.t key value
let op_String_Access     = Map.sel
let op_String_Assignment = Map.upd

(** Memory framing **)

(*
unfold let in_mem (addr:int) (m:mem) : bool = m `Map.contains` addr

let disjoint (ptr1:int) (num_bytes1:int) (ptr2:int) (num_bytes2:int) =
    ptr1 + num_bytes1 <= ptr2 \/ ptr2 + num_bytes2 <= ptr1

let validSrcAddrs (mem:mem) (addr:int) (size:int) (num_bytes:int) =
    size == 64 /\
    (forall (a:int) . {:pattern (mem `Map.contains` a)} addr <= a && a < addr+num_bytes && (a - addr) % 8 = 0 ==> mem `Map.contains` a)

let memModified (old_mem:mem) (new_mem:mem) (ptr:int) (num_bytes) =
    (forall (a:int) . {:pattern (new_mem `Map.contains` a)} old_mem `Map.contains` a <==> new_mem `Map.contains` a) /\
    (forall (a:int) . {:pattern (new_mem.[a]) \/ Map.sel new_mem a} a < ptr || a >= ptr + num_bytes ==> old_mem.[a] == new_mem.[a])
*)   

val eval_code (c:va_code) (s0:va_state) (f0:va_fuel) (sN:va_state) : Type0
val eval_while_inv (c:va_code) (s0:va_state) (fW:va_fuel) (sW:va_state) : Type0

(* ok for now but no need to actually expose the definition.
   instead expose lemmas about it *)
let va_state_eq (s0:va_state) (s1:va_state) : Type0 = state_eq s0 s1

let va_require_total (c0:va_code) (c1:va_code) (s0:va_state) : Type0 =
  c0 == c1

let va_ensure_total (c0:va_code) (s0:va_state) (s1:va_state) (f1:va_fuel) : Type0 =
  eval_code c0 s0 f1 s1

val eval_ocmp : s:va_state -> c:ocmp -> GTot bool
unfold let va_evalCond (b:ocmp) (s:va_state) : GTot bool = eval_ocmp s b

val valid_ocmp : c:ocmp -> s:va_state -> GTot bool

val lemma_cmp_eq : s:va_state -> o1:va_src_operand -> o2:va_src_operand -> Lemma
  (requires True)
  (ensures  (eval_ocmp s (va_cmp_eq o1 o2)) <==> (va_eval_operand_uint64 s o1 == va_eval_operand_uint64 s o2))
  [SMTPat (eval_ocmp s (va_cmp_eq o1 o2))]

val lemma_cmp_ne : s:va_state -> o1:va_src_operand -> o2:va_src_operand -> Lemma
  (requires True)
  (ensures  (eval_ocmp s (va_cmp_ne o1 o2)) <==> (va_eval_operand_uint64 s o1 <> va_eval_operand_uint64 s o2))
  [SMTPat (eval_ocmp s (va_cmp_ne o1 o2))]

val lemma_cmp_le : s:va_state -> o1:va_src_operand -> o2:va_src_operand -> Lemma
  (requires True)
  (ensures  (eval_ocmp s (va_cmp_le o1 o2)) <==> (va_eval_operand_uint64 s o1 <= va_eval_operand_uint64 s o2))
  [SMTPat (eval_ocmp s (va_cmp_le o1 o2))]

val lemma_cmp_ge : s:va_state -> o1:va_src_operand -> o2:va_src_operand -> Lemma
  (requires True)
  (ensures  (eval_ocmp s (va_cmp_ge o1 o2)) <==> (va_eval_operand_uint64 s o1 >= va_eval_operand_uint64 s o2))
  [SMTPat (eval_ocmp s (va_cmp_ge o1 o2))]

val lemma_cmp_lt : s:va_state -> o1:va_src_operand -> o2:va_src_operand -> Lemma
  (requires True)
  (ensures  (eval_ocmp s (va_cmp_lt o1 o2)) <==> (va_eval_operand_uint64 s o1 < va_eval_operand_uint64 s o2))
  [SMTPat (eval_ocmp s (va_cmp_lt o1 o2))]

val lemma_cmp_gt : s:va_state -> o1:va_src_operand -> o2:va_src_operand -> Lemma
  (requires True)
  (ensures  (eval_ocmp s (va_cmp_gt o1 o2)) <==> (va_eval_operand_uint64 s o1 > va_eval_operand_uint64 s o2))
  [SMTPat (eval_ocmp s (va_cmp_gt o1 o2))]

val lemma_valid_cmp_eq : s:va_state -> o1:va_src_operand -> o2:va_src_operand -> Lemma
  (requires True)
  (ensures  (valid_operand o1 s /\ valid_operand o2 s) ==> (valid_ocmp (va_cmp_eq o1 o2) s))
  [SMTPat (valid_ocmp (va_cmp_eq o1 o2) s)]

val lemma_valid_cmp_ne : s:va_state -> o1:va_src_operand -> o2:va_src_operand -> Lemma
  (requires True)
  (ensures (valid_operand o1 s /\ valid_operand o2 s) ==> (valid_ocmp (va_cmp_ne o1 o2) s))
  [SMTPat (valid_ocmp (va_cmp_ne o1 o2) s)]

val lemma_valid_cmp_le : s:va_state -> o1:va_src_operand -> o2:va_src_operand -> Lemma
  (requires True)
  (ensures (valid_operand o1 s /\ valid_operand o2 s) ==> (valid_ocmp (va_cmp_le o1 o2) s))
  [SMTPat (valid_ocmp (va_cmp_le o1 o2) s)]

val lemma_valid_cmp_ge : s:va_state -> o1:va_src_operand -> o2:va_src_operand -> Lemma
  (requires True)
  (ensures (valid_operand o1 s /\ valid_operand o2 s) ==> (valid_ocmp (va_cmp_ge o1 o2) s))
  [SMTPat (valid_ocmp (va_cmp_ge o1 o2) s)]

val lemma_valid_cmp_lt : s:va_state -> o1:va_src_operand -> o2:va_src_operand -> Lemma
  (requires True)
  (ensures (valid_operand o1 s /\ valid_operand o2 s) ==> (valid_ocmp (va_cmp_lt o1 o2) s))
  [SMTPat (valid_ocmp (va_cmp_lt o1 o2) s)]

val lemma_valid_cmp_gt : s:va_state -> o1:va_src_operand -> o2:va_src_operand -> Lemma
  (requires True)
  (ensures (valid_operand o1 s /\ valid_operand o2 s) ==> (valid_ocmp (va_cmp_gt o1 o2) s))
  [SMTPat (valid_ocmp (va_cmp_gt o1 o2) s)]

val va_lemma_merge_total (b0:va_codes) (s0:va_state) (f0:va_fuel) (sM:va_state) (fM:va_fuel) (sN:va_state) : Ghost (fN:va_fuel)
  (requires
    Cons? b0 /\
    eval_code (Cons?.hd b0) s0 f0 sM /\
    eval_code (va_Block (Cons?.tl b0)) sM fM sN
  )
  (ensures (fun fN ->
    eval_code (va_Block b0) s0 fN sN
  ))

val va_lemma_empty_total (s0:va_state) (bN:va_codes) : Ghost ((sM:va_state) * (fM:va_fuel))
  (requires True)
  (ensures (fun (sM, fM) ->
    s0 == sM /\
    eval_code (va_Block []) s0 fM sM
  ))

val va_lemma_ifElse_total (ifb:ocmp) (ct:va_code) (cf:va_code) (s0:va_state) : Ghost (bool * va_state * va_state * va_fuel)
  (requires True)
  (ensures  (fun (cond, sM, sN, f0) ->
    cond == eval_ocmp s0 ifb /\
    sM == {s0 with trace = BranchPredicate(cond)::s0.trace}
  ))

val va_lemma_ifElseTrue_total (ifb:ocmp) (ct:va_code) (cf:va_code) (s0:va_state) (f0:va_fuel) (sM:va_state) : Lemma
  (requires
    valid_ocmp ifb s0 /\
    eval_ocmp s0 ifb /\
    eval_code ct ({s0 with trace = BranchPredicate(true)::s0.trace}) f0 sM
  )
  (ensures
    eval_code (IfElse ifb ct cf) s0 f0 sM
  )

val va_lemma_ifElseFalse_total (ifb:ocmp) (ct:va_code) (cf:va_code) (s0:va_state) (f0:va_fuel) (sM:va_state) : Lemma
  (requires
    valid_ocmp ifb s0 /\
    not (eval_ocmp s0 ifb) /\
    eval_code cf ({s0 with trace = BranchPredicate(false)::s0.trace}) f0 sM
  )
  (ensures
    eval_code (IfElse ifb ct cf) s0 f0 sM
  )

let va_whileInv_total (b:ocmp) (c:va_code) (s0:va_state) (sN:va_state) (f0:va_fuel) : Type0 =
  eval_while_inv (While b c) s0 f0 sN

val va_lemma_while_total (b:ocmp) (c:va_code) (s0:va_state) : Ghost ((s1:va_state) * (f1:va_fuel))
  (requires True)
  (ensures fun (s1, f1) ->
    s1 == s0 /\
    eval_while_inv (While b c) s1 f1 s1
  )

val va_lemma_whileTrue_total (b:ocmp) (c:va_code) (s0:va_state) (sW:va_state) (fW:va_fuel) : Ghost ((s1:va_state) * (f1:va_fuel))
  (requires eval_ocmp sW b /\ valid_ocmp b sW)
  (ensures fun (s1, f1) -> s1 == {sW with trace = BranchPredicate(true)::sW.trace} /\ f1 == fW)

val va_lemma_whileFalse_total (b:ocmp) (c:va_code) (s0:va_state) (sW:va_state) (fW:va_fuel) : Ghost ((s1:va_state) * (f1:va_fuel))
  (requires
    valid_ocmp b sW /\
    not (eval_ocmp sW b) /\
    eval_while_inv (While b c) s0 fW sW
  )
  (ensures fun (s1, f1) ->
    s1 == {sW with trace = BranchPredicate(false)::sW.trace} /\
    eval_code (While b c) s0 f1 s1
  )

val va_lemma_whileMerge_total (c:va_code) (s0:va_state) (f0:va_fuel) (sM:va_state) (fM:va_fuel) (sN:va_state) : Ghost (fN:va_fuel)
  (requires
    While? c /\
    sN.ok /\
    valid_ocmp (While?.whileCond c) sM /\
    eval_ocmp sM (While?.whileCond c) /\
    eval_while_inv c s0 f0 sM /\
    eval_code (While?.whileBody c) ({sM with trace = BranchPredicate(true)::sM.trace}) fM sN
  )
  (ensures (fun fN ->
    eval_while_inv c s0 fN sN
  ))

(* maybe we want these to be transparent*)
val logxor64 : (x:nat64) -> (y:nat64) -> nat64
val logand64 : (x:nat64) -> (y:nat64) -> nat64
val logand128 : (x:nat128) -> (y:nat128) -> nat128
val shift_left64 : (x:nat64) -> (amt:nat64) -> nat64
val shift_right64 : (x:nat64) -> (amt:nat64) -> nat64

val reveal_logand128 (x y:nat128) : Lemma
    (requires True)
    (ensures logand128 x y == FStar.UInt.logand #128 x y)

(*
val printer : Type0
val print_string : string -> FStar.All.ML unit
val print_header : printer -> FStar.All.ML unit
val print_proc : (name:string) -> (code:va_code) -> (label:int) -> (p:printer) -> FStar.All.ML unit
val print_footer : printer -> FStar.All.ML unit
val masm : printer
val gcc : printer
*)
#endverbatim

#verbatim implementation
module X64.Vale.Decls
open X64.Machine_s
open X64.Vale
open X64.Vale.State_i
open X64.Vale.StateLemmas_i
open FStar.UInt
module S = X64.Semantics_s
module TS = X64.Taint_Semantics_s
module P = X64.Print_s

#reset-options "--z3cliopt smt.arith.nl=true"
let lemma_mul_in_bounds (x y:nat64) : Lemma (requires x `op_Multiply` y < nat64_max) (ensures FStar.UInt.mul_mod #64 x y == x `op_Multiply` y) = ()

#reset-options "--z3cliopt smt.arith.nl=true --using_facts_from Prims --using_facts_from FStar.Math"
let lemma_mul_nat (x:nat) (y:nat) : Lemma (ensures 0 <= (x `op_Multiply` y)) = ()
#reset-options "--initial_fuel 2 --max_fuel 2"

let cf = Lemmas_i.cf
let ins = TS.tainted_ins
type ocmp = TS.tainted_ocmp
type va_fuel = nat
let va_fuel_default () = 0

let va_cmp_eq o1 o2 = TS.TaintedOCmp (S.OEq o1 o2) Public
let va_cmp_ne o1 o2 = TS.TaintedOCmp (S.ONe o1 o2) Public
let va_cmp_le o1 o2 = TS.TaintedOCmp (S.OLe o1 o2) Public
let va_cmp_ge o1 o2 = TS.TaintedOCmp (S.OGe o1 o2) Public
let va_cmp_lt o1 o2 = TS.TaintedOCmp (S.OLt o1 o2) Public
let va_cmp_gt o1 o2 = TS.TaintedOCmp (S.OGt o1 o2) Public

let eval_code = Lemmas_i.eval_code
let eval_while_inv = Lemmas_i.eval_while_inv
let eval_ocmp = Lemmas_i.eval_ocmp
let valid_ocmp = Lemmas_i.valid_ocmp

unfold let va_eval_ins = Lemmas_i.eval_ins

let lemma_cmp_eq s o1 o2 = ()
let lemma_cmp_ne s o1 o2 = ()
let lemma_cmp_le s o1 o2 = ()
let lemma_cmp_ge s o1 o2 = ()
let lemma_cmp_lt s o1 o2 = ()
let lemma_cmp_gt s o1 o2 = ()

let lemma_valid_cmp_eq s o1 o2 = ()
let lemma_valid_cmp_ne s o1 o2 = ()
let lemma_valid_cmp_le s o1 o2 = ()
let lemma_valid_cmp_ge s o1 o2 = ()
let lemma_valid_cmp_lt s o1 o2 = ()
let lemma_valid_cmp_gt s o1 o2 = ()

let va_lemma_merge_total = Lemmas_i.lemma_merge_total
let va_lemma_empty_total = Lemmas_i.lemma_empty_total
let va_lemma_ifElse_total = Lemmas_i.lemma_ifElse_total
let va_lemma_ifElseTrue_total = Lemmas_i.lemma_ifElseTrue_total
let va_lemma_ifElseFalse_total = Lemmas_i.lemma_ifElseFalse_total
let va_lemma_while_total = Lemmas_i.lemma_while_total
let va_lemma_whileTrue_total = Lemmas_i.lemma_whileTrue_total
let va_lemma_whileFalse_total = Lemmas_i.lemma_whileFalse_total
let va_lemma_whileMerge_total = Lemmas_i.lemma_whileMerge_total

let logxor64 (x:nat64) (y:nat64) : nat64 =
  FStar.UInt.logxor #64 x y

let logand64 (x:nat64) (y:nat64) : nat64 =
  FStar.UInt.logand #64 x y

let logand128 (x:nat128) (y:nat128) : nat128 =
  FStar.UInt.logand #128 x y
(*
  if FStar.UInt.fits x 64
  && FStar.UInt.fits y 64
  then FStar.UInt.logand #64 x y
  else 0
*)

let shift_left64 (x:nat64) (amt:nat64) : nat64 =
  FStar.UInt.shift_left #64 x amt

let shift_right64 (x:nat64) (amt:nat64) : nat64 =
  FStar.UInt.shift_right #64 x amt

let reveal_logand128 (x y:nat128) = ()

(*
let printer = P.printer
let print_string = FStar.IO.print_string
let print_header = P.print_header
let print_proc = P.print_proc
let print_footer = P.print_footer
let masm = P.masm
let gcc = P.gcc
*)

#set-options "--initial_fuel 4 --max_fuel 4 --z3rlimit 20"
#endverbatim

var{:state ok()} ok:bool;
var{:state reg(Rax)} rax:int;
var{:state reg(Rbx)} rbx:int;
var{:state reg(Rcx)} rcx:int;
var{:state reg(Rdx)} rdx:int;
var{:state reg(Rsi)} rsi:int;
var{:state reg(Rdi)} rdi:int;
var{:state reg(Rbp)} rbp:int;
var{:state reg(Rsp)} rsp:int;
var{:state reg(R8)}  r8:int;
var{:state reg(R9)}  r9:int;
var{:state reg(R10)} r10:int;
var{:state reg(R11)} r11:int;
var{:state reg(R12)} r12:int;
var{:state reg(R13)} r13:int;
var{:state reg(R14)} r14:int;
var{:state reg(R15)} r15:int;
var{:state flags()} efl:int;
var{:state mem()} mem:int;
var{:state trace()} trace:int;
var{:state memTaint()} memTaint:int;

procedure{:operand} Mem_in(operand base:int, inline offset:int, ghost b:buffer64, ghost index:int) returns(operand o:int)
    reads
        mem;
    extern;

procedure{:instruction Ins(TS.TaintedIns(tuple(S.Mov64(dst,src),list(dst), list(src)), Public))}{:fast_instruction} Mov64(inout dst_operand dst:uint64, src_operand src:uint64)
    ensures
        dst == old(src);
{
}

procedure{:instruction Ins(TS.TaintedIns(tuple(S.Mov64(dst, OMem(MReg(get_reg(src), offset))), list(dst), list(OMem(MReg(get_reg(src), offset)))), t))}{:fast_instruction} Load64_buffer(
    out dst_operand dst:uint64,
        reg_operand src:uint64,
        inline offset:int,
        inline t:taint,
        ghost b:buffer64,
        ghost index:int)
    reads
        mem;
        memTaint;
    modifies
        trace;
    requires
        valid_src_addr(mem, b, index);
        valid_taint_ptr(src + offset, memTaint, t);
        src + offset == buffer_addr(b) + 8 * index;
    ensures
        valid_src_addr(mem, b, index);
        valid_taint_ptr(old(src) + offset, memTaint, t);
        dst == buffer64_read(b, index, mem);
{
    lemma_valid_mem64(b, index, mem);
    lemma_load_mem64(b, index, mem);
}

procedure{:instruction Ins(TS.TaintedIns(tuple(S.Mov64(OMem(MReg(get_reg(dst), offset)), src), list(OMem(MReg(get_reg(dst), offset))), list(src)), t))}{:fast_instruction} Store64_buffer(
        reg_operand dst:uint64,
        src_operand src:uint64,
        inline offset:int,
        inline t:taint,
        ghost b:buffer64,
        ghost index:int)
    modifies
        mem;
        memTaint;
        trace;
    requires
        valid_dst_addr(mem, b, index);
        dst + offset == buffer_addr(b) + 8 * index;
    ensures
        valid_dst_addr(mem, b, index);
        valid_taint_ptr(dst + offset, memTaint, t);
        modifies_mem(loc_buffer(b), old(mem), mem);
        modifies_memTaint(dst + offset, old(memTaint), memTaint);
        mem == old(buffer64_write(b, index, src, mem));
{
    lemma_valid_mem64(b, index, old(mem));
    lemma_store_mem64(b, index, old(src), old(mem));
}

procedure{:instruction Ins(TS.TaintedIns(tuple(S.Add64(dst,src), list(dst), list(dst, src)), Public))} Add64(inout dst_operand dst:uint64, src_operand src:uint64)
    modifies
        efl;
    requires
        src + dst < nat64_max;
    ensures
        eq_int(dst, old(dst + src));
{
}

procedure{:instruction Ins(TS.TaintedIns(tuple(S.Add64(dst,src), list(dst), list(dst, src)), Public))}{:fast_instruction} Add64Wrap(inout dst_operand dst:uint64, src_operand src:uint64)
    modifies
        efl;
    ensures
        dst == old(add_wrap(dst, src));
        cf(efl) == old(dst + src >= nat64_max);
{
}

procedure{:instruction Ins(TS.TaintedIns(tuple(S.Add64(dst,OMem(MReg(get_reg(src), offset))), list(dst), list(dst, OMem(MReg(get_reg(src), offset)))), t))}{:fast_instruction} Add64Wrap_Mem(
    inout dst_operand dst:uint64,
    reg_operand src:uint64,
    inline offset:int,
    inline t:taint,
    ghost b:buffer64,
    ghost index:int)
    reads
        memTaint; mem;
    modifies
        efl; trace;
    requires
        valid_src_addr(mem, b, index);
        valid_taint_ptr(src + offset, memTaint, t);
        src + offset == buffer_addr(b) + 8 * index;
    ensures
        valid_src_addr(mem, b, index);
        valid_taint_ptr(old(src) + offset, memTaint, t);
        dst == old(add_wrap(dst, buffer64_read(b, index, mem)));
        cf(efl) == old(dst + buffer64_read(b, index, mem) >= nat64_max);
{
    lemma_valid_mem64(b, index, mem);
    lemma_load_mem64(b, index, mem);
}

procedure{:instruction Ins(TS.TaintedIns(tuple(S.AddLea64(dst, src1, src2), list(dst), list(dst, src1, src2)), Public))} AddLea64(out dst_operand dst:uint64, src_operand src1:uint64, src_operand src2:uint64)
    requires
        src1 + src2 < nat64_max;
    ensures
        eq_int(dst, old(src1) + old(src2));
{
}

procedure{:instruction Ins(TS.TaintedIns(tuple(S.AddCarry64(dst, src), list(dst), list(dst, src)), Public))}{:fast_instruction} Adc64Wrap(inout dst_operand dst:uint64, src_operand src:uint64)
    modifies
        efl;
    ensures
        dst == old(add_wrap(add_wrap(dst, src), (if cf(efl) then 1 else 0)));
        cf(efl) == old(dst + src + (if cf(efl) then 1 else 0)) >= nat64_max;
{
}

procedure{:instruction Ins(TS.TaintedIns(tuple(S.AddCarry64(dst,OMem(MReg(get_reg(src), offset))), list(dst), list(dst, OMem(MReg(get_reg(src), offset)))), t))}{:fast_instruction} Adc64Wrap_Mem(
    inout dst_operand dst:uint64,
    reg_operand src:uint64,
    inline offset:int,
    inline t:taint,
    ghost b:buffer64,
    ghost index:int)
    reads
        memTaint; mem;
    modifies
        efl; trace;
    requires
        valid_src_addr(mem, b, index);
        valid_taint_ptr(src + offset, memTaint, t);
        src + offset == buffer_addr(b) + 8 * index;
    ensures
        valid_src_addr(mem, b, index);
        valid_taint_ptr(old(src) + offset, memTaint, t);
        dst == old(add_wrap(add_wrap(dst, buffer64_read(b, index, mem)), (if cf(efl) then 1 else 0)));
        cf(efl) == old(dst + buffer64_read(b, index, mem) + (if cf(efl) then 1 else 0)) >= nat64_max;
{
    lemma_valid_mem64(b, index, mem);
    lemma_load_mem64(b, index, mem);
}

procedure{:instruction Ins(TS.TaintedIns(tuple(S.Sub64(dst, src), list(dst), list(dst, src)), Public))}{:fast_instruction} Sub64(inout dst_operand dst:uint64, src_operand src:uint64)
    requires
        0 <= dst - src;
    modifies 
        efl;
    ensures
        eq_int(dst, old(dst) - old(src));
{
}

procedure{:instruction Ins(TS.TaintedIns(tuple(S.Sub64(dst, src), list(dst), list(dst, src)), Public))} Sub64Wrap(inout dst_operand dst:uint64, src_operand src:uint64)
    modifies
        efl;
    ensures
        dst == old(dst - src) % nat64_max;
{
}

#verbatim
let lemma_fundamental_div_mod (a b:nat64) :
  Lemma (nat64_max `op_Multiply` (FStar.UInt.mul_div #64 a b) + (FStar.UInt.mul_mod #64 a b) == a `op_Multiply` b)
  =
  ()
#endverbatim

procedure{:instruction Ins(TS.TaintedIns(tuple(S.Mul64(src), list(OReg(Rax), OReg(Rdx)), list(OReg(Rax), src)), Public))}{:fast_instruction} Mul64Wrap(src_operand src:uint64)
    modifies
        efl;
        rax;
        rdx;
    ensures
        nat64_max * rdx + rax == old(rax * src);
{
    lemma_fundamental_div_mod(old(rax), old(src));
}

procedure{:instruction Ins(TS.TaintedIns(tuple(S.IMul64(dst, src), list(dst), list(dst, src)), Public))}{:fast_instruction} IMul64(inout dst_operand dst:uint64, src_operand src:uint64)
    requires
        dst * src < nat64_max;
    modifies
        efl;
    ensures
        eq_int(dst, (old(dst * src)));
{
    lemma_mul_nat(old(dst), old(src));
    lemma_mul_in_bounds(old(dst), old(src));
}

procedure{:instruction Ins(TS.TaintedIns(tuple(S.Xor64(dst, src), list(dst), list(dst, src)), Public))} Xor64(inout dst_operand dst:uint64, src_operand src:uint64)
    modifies 
        efl;
    ensures
        dst == old(logxor64(dst,src));
{
}

procedure{:instruction Ins(TS.TaintedIns(tuple(S.And64(dst, src), list(dst), list(dst, src)), Public))}{:fast_instruction} And64(inout dst_operand dst:uint64, src_operand src:uint64)
    modifies 
        efl;
    ensures
        dst == old(logand64(dst,src));
{
}

procedure{:instruction Ins(TS.TaintedIns(tuple(S.Shl64(dst, amt), list(dst), list(dst, amt)), Public))} Shl64(inout dst_operand dst:uint64, shift_amt amt:uint64)
    modifies
        efl;
//    requires
//        0 <= src < 64;
    ensures
        dst == old(shift_left64(dst, amt));
{
}

procedure{:instruction Ins(TS.TaintedIns(tuple(S.Shr64(dst, amt), list(dst), list(dst, amt)), Public))}{:fast_instruction} Shr64(inout dst_operand dst:uint64, shift_amt amt:uint64)
    modifies
        efl;
    ensures
        dst == old(shift_right64(dst, amt));
{
}
