// Vale options: -fstarText -conciseLemmas=false

#verbatim
module Decls_alt

open Semantics_alt
open Vale_alt

#reset-options "--z3rlimit 200"

let add_wrap (x:int) (y:int) = if x + y < nat64_max then x + y else x + y - nat64_max

#endverbatim

var{:state ok()} ok:bool;
var{:state reg(Rax)} rax:int;
var{:state reg(Rbx)} rbx:int;
var{:state reg(Rcx)} rcx:int;
var{:state reg(Rdx)} rdx:int;
var{:state flags()} efl:int;
var{:state mem()} mem:int;

procedure Mov64(inout dst_operand dst:uint64, operand src:uint64)
    ensures
        dst == old(src);
    extern;

procedure Add64Wrap(inout dst_operand dst:uint64, operand src:uint64)
    modifies
        efl;
    ensures
        dst == old(add_wrap(dst, src));
        cf(efl) == old(dst + src >= nat64_max);
    extern;

procedure AddLea64(out dst_operand dst:uint64, operand src1:uint64, operand src2:uint64)
    requires
        src1 + src2 < nat64_max;
    ensures
        dst == old(src1) + old(src2);
    extern;

procedure Adc64Wrap(inout dst_operand dst:uint64, operand src:uint64)
    modifies
        efl;
    ensures
        dst == old(add+wrap(add_wrap(dst, src), (if cf(efl) then 1 else 0)));
        cf(efl) == old(dst + src + (if cf(efl) then 1 else 0)) >= nat64_max;
    extern;

procedure Sub64(inout dst_operand dst:uint64, operand src:uint64)
    requires
        0 <= dst - src;
    modifies 
        efl;
    ensures
        dst == old(dst) - old(src);
    extern;

procedure Sub64Wrap(inout dst_operand dst:uint64, operand src:uint64)
    modifies
        efl;
    ensures
        dst == old(dst - src) % nat64_max;
    extern;

procedure Mul64Wrap(operand src:uint64)
    modifies
        efl;
        rax;
        rdx;
    ensures
        nat64_max * rdx + rax == old(rax * src);
    extern;

procedure IMul64Wrap(inout dst_operand dst:uint64, operand src:uint64)
    requires
        dst * src < nat64_max;
    modifies
        efl;
    ensures
        // dst == old(dst * src) % nat64_max;
        dst == old(dst * src);
    extern;

#verbatim
assume val logxor64 : (x:nat64) -> (y:nat64) -> nat64
assume val logand64 : (x:nat64) -> (y:nat64) -> nat64
assume val shift_left64 : (x:nat64) -> (amt:nat64) -> nat64
assume val shift_right64 : (x:nat64) -> (amt:nat64) -> nat64
#endverbatim

procedure Xor64(inout dst_operand dst:uint64, operand src:uint64)
    modifies 
        efl;
    ensures
        dst == old(logxor64(dst,src));
    extern;

procedure And64(inout dst_operand dst:uint64, operand src:uint64)
    modifies 
        efl;
    ensures
        dst == old(logand64(dst,src));
    extern;

procedure Shl64(inout dst_operand dst:uint64, shift_amt amt:uint64)
    modifies
        efl;
//    requires
//        0 <= src < 64;
    ensures
        dst == old(shift_left64(dst, amt));
    extern;

procedure Shr64(inout dst_operand dst:uint64, shift_amt amt:uint64)
    modifies
        efl;
    ensures
        dst == old(shift_right64(dst, amt));
    extern;

#verbatim
assume val va_code_Mov64 : dst:va_dst_operand -> src:va_operand -> Tot va_code

assume val va_lemma_Mov64 : va_b0:va_codes -> va_s0:va_state -> va_sN:va_state ->
  dst:va_dst_operand -> src:va_operand
  -> Ghost ((va_sM:va_state))
  (requires (phase_1_ (va_require va_b0 (va_code_Mov64 dst src) va_s0 va_sN) /\
    phase_1_ (va_is_dst_dst_operand_uint64 dst va_s0) /\ phase_1_ (va_is_src_operand_uint64 src va_s0) /\ (va_get_ok
    va_s0)))
  (ensures (fun ((va_sM:va_state)) -> ((va_ensure va_b0 va_s0 va_sM va_sN) /\ (va_get_ok va_sM) /\
    (va_eval_dst_operand_uint64 va_sM dst) == (va_eval_operand_uint64 va_s0 src) /\ (va_state_eq
    va_sM (va_update_ok va_sM (va_update_dst_operand dst va_sM va_s0))))))

assume val va_code_Add64Wrap : dst:va_dst_operand -> src:va_operand -> Tot va_code

assume val va_lemma_Add64Wrap : va_b0:va_codes -> va_s0:va_state -> va_sN:va_state ->
  dst:va_dst_operand -> src:va_operand
  -> Ghost ((va_sM:va_state))
  (requires (phase_1_ (va_require va_b0 (va_code_Add64Wrap dst src) va_s0 va_sN) /\
    phase_1_ (va_is_dst_dst_operand_uint64 dst va_s0) /\ phase_1_ (va_is_src_operand_uint64 src va_s0) /\ (va_get_ok
    va_s0)))
  (ensures (fun ((va_sM:va_state)) -> ((va_ensure va_b0 va_s0 va_sM va_sN) /\ (va_get_ok va_sM) /\
    (va_eval_dst_operand_uint64 va_sM dst) == (add_wrap (va_eval_dst_operand_uint64 va_s0 dst)
    (va_eval_operand_uint64 va_s0 src)) /\
    (cf (va_get_flags va_sM)) == (((va_eval_dst_operand_uint64 va_s0 dst)
    + (va_eval_operand_uint64 va_s0 src)) >= nat64_max) /\ (va_state_eq va_sM
    (va_update_flags va_sM (va_update_ok va_sM (va_update_dst_operand dst va_sM va_s0)))))))

assume val va_code_AddLea64 : dst:va_dst_operand -> src1:va_operand -> src2:va_operand -> Tot va_code

assume val va_lemma_AddLea64 : va_b0:va_codes -> va_s0:va_state -> va_sN:va_state ->
  dst:va_dst_operand -> src1:va_operand -> src2:va_operand
  -> Ghost ((va_sM:va_state))
  (requires (phase_1_ (va_require va_b0 (va_code_AddLea64 dst src1 src2) va_s0 va_sN) /\
    phase_1_ (va_is_dst_dst_operand_uint64 dst va_s0) /\ phase_1_ (va_is_src_operand_uint64 src1 va_s0) /\
    phase_1_ (va_is_src_operand_uint64 src2 va_s0) /\ (va_get_ok va_s0) /\ (va_eval_operand_uint64 va_s0
    src1) + (va_eval_operand_uint64 va_s0 src2) < nat64_max))
  (ensures (fun ((va_sM:va_state)) -> ((va_ensure va_b0 va_s0 va_sM va_sN) /\ (va_get_ok va_sM) /\
    (va_eval_dst_operand_uint64 va_sM dst) == (va_eval_operand_uint64 va_s0 src1) +
    (va_eval_operand_uint64 va_s0 src2) /\ (va_state_eq va_sM (va_update_ok va_sM
    (va_update_dst_operand dst va_sM va_s0))))))

assume val va_code_Adc64Wrap : dst:va_dst_operand -> src:va_operand -> Tot va_code

assume val va_lemma_Adc64Wrap : va_b0:va_codes -> va_s0:va_state -> va_sN:va_state ->
  dst:va_dst_operand -> src:va_operand
  -> Ghost ((va_sM:va_state))
  (requires (phase_1_ (va_require va_b0 (va_code_Adc64Wrap dst src) va_s0 va_sN) /\
    phase_1_ (va_is_dst_dst_operand_uint64 dst va_s0) /\ phase_1_ (va_is_src_operand_uint64 src va_s0) /\ (va_get_ok
    va_s0)))
  (ensures (fun ((va_sM:va_state)) -> ((va_ensure va_b0 va_s0 va_sM va_sN) /\ (va_get_ok va_sM) /\
    (va_eval_dst_operand_uint64 va_sM dst) == (add_wrap (add_wrap (va_eval_dst_operand_uint64 va_s0 dst)
    (va_eval_operand_uint64 va_s0 src)) (if (cf (va_get_flags va_s0)) then 1 else 0))
    /\ (cf (va_get_flags va_sM)) == (((va_eval_dst_operand_uint64 va_s0 dst)
    + (va_eval_operand_uint64 va_s0 src)) + (if (cf (va_get_flags va_s0)) then 1 else 0) >=
    nat64_max) /\ (va_state_eq va_sM (va_update_flags va_sM (va_update_ok va_sM
    (va_update_dst_operand dst va_sM va_s0)))))))

assume val va_code_Sub64 : dst:va_dst_operand -> src:va_operand -> Tot va_code

assume val va_lemma_Sub64 : va_b0:va_codes -> va_s0:va_state -> va_sN:va_state ->
  dst:va_dst_operand -> src:va_operand
  -> Ghost ((va_sM:va_state))
  (requires (phase_1_ (va_require va_b0 (va_code_Sub64 dst src) va_s0 va_sN) /\
    phase_1_ (va_is_dst_dst_operand_uint64 dst va_s0) /\ phase_1_ (va_is_src_operand_uint64 src va_s0) /\ (va_get_ok
    va_s0) /\ 0 <= (va_eval_dst_operand_uint64 va_s0 dst) - (va_eval_operand_uint64 va_s0 src)))
  (ensures (fun ((va_sM:va_state)) -> ((va_ensure va_b0 va_s0 va_sM va_sN) /\ (va_get_ok va_sM) /\
    (va_eval_dst_operand_uint64 va_sM dst) == (va_eval_dst_operand_uint64 va_s0 dst) -
    (va_eval_operand_uint64 va_s0 src) /\ (va_state_eq va_sM (va_update_flags va_sM (va_update_ok
    va_sM (va_update_dst_operand dst va_sM va_s0)))))))

assume val va_code_Sub64Wrap : dst:va_dst_operand -> src:va_operand -> Tot va_code

assume val va_lemma_Sub64Wrap : va_b0:va_codes -> va_s0:va_state -> va_sN:va_state ->
  dst:va_dst_operand -> src:va_operand
  -> Ghost ((va_sM:va_state))
  (requires (phase_1_ (va_require va_b0 (va_code_Sub64Wrap dst src) va_s0 va_sN) /\
    phase_1_ (va_is_dst_dst_operand_uint64 dst va_s0) /\ phase_1_ (va_is_src_operand_uint64 src va_s0) /\ (va_get_ok
    va_s0)))
  (ensures (fun ((va_sM:va_state)) -> ((va_ensure va_b0 va_s0 va_sM va_sN) /\ (va_get_ok va_sM) /\
    (va_eval_dst_operand_uint64 va_sM dst) == ((va_eval_dst_operand_uint64 va_s0 dst) -
    (va_eval_operand_uint64 va_s0 src)) `op_Modulus` nat64_max /\ (va_state_eq va_sM
    (va_update_flags va_sM (va_update_ok va_sM (va_update_dst_operand dst va_sM va_s0)))))))

assume val va_code_Mul64Wrap : src:va_operand -> Tot va_code

assume val va_lemma_Mul64Wrap : va_b0:va_codes -> va_s0:va_state -> va_sN:va_state ->
  src:va_operand
  -> Ghost ((va_sM:va_state))
  (requires (phase_1_ (va_require va_b0 (va_code_Mul64Wrap src) va_s0 va_sN) /\ phase_1_ (va_is_src_operand_uint64
    src va_s0) /\ (va_get_ok va_s0)))
  (ensures (fun ((va_sM:va_state)) -> ((va_ensure va_b0 va_s0 va_sM va_sN) /\ (va_get_ok va_sM) /\
    (va_get_reg Rax va_sM) + (nat64_max `op_Multiply` (va_get_reg Rdx va_sM)) ==
      ((va_get_reg Rax va_s0) `op_Multiply` (va_eval_operand_uint64 va_s0 src)) /\
    (va_state_eq va_sM
    (va_update_reg Rdx va_sM (va_update_reg Rax va_sM (va_update_flags va_sM (va_update_ok va_sM
    va_s0))))))))

assume val va_code_IMul64Wrap : dst:va_dst_operand -> src:va_operand -> Tot va_code

assume val va_lemma_IMul64Wrap : va_b0:va_codes -> va_s0:va_state -> va_sN:va_state ->
  dst:va_dst_operand -> src:va_operand
  -> Ghost ((va_sM:va_state))
  (requires (phase_1_ (va_require va_b0 (va_code_IMul64Wrap dst src) va_s0 va_sN) /\
    phase_1_ (va_is_dst_dst_operand_uint64 dst va_s0) /\ phase_1_ (va_is_src_operand_uint64 src va_s0) /\
    ((va_eval_dst_operand_uint64 va_s0 dst) `op_Multiply` (va_eval_operand_uint64 va_s0 src)) < nat64_max /\
    (va_get_ok va_s0)))
  (ensures (fun ((va_sM:va_state)) -> ((va_ensure va_b0 va_s0 va_sM va_sN) /\ (va_get_ok va_sM) /\
    (va_eval_dst_operand_uint64 va_sM dst) == ((va_eval_dst_operand_uint64 va_s0 dst) `op_Multiply`
    (va_eval_operand_uint64 va_s0 src)) /\ (va_state_eq va_sM
    (va_update_flags va_sM (va_update_ok va_sM (va_update_dst_operand dst va_sM va_s0)))))))

assume val va_code_Xor64 : dst:va_dst_operand -> src:va_operand -> Tot va_code

assume val va_lemma_Xor64 : va_b0:va_codes -> va_s0:va_state -> va_sN:va_state ->
  dst:va_dst_operand -> src:va_operand
  -> Ghost ((va_sM:va_state))
  (requires (phase_1_ (va_require va_b0 (va_code_Xor64 dst src) va_s0 va_sN) /\
    phase_1_ (va_is_dst_dst_operand_uint64 dst va_s0) /\ phase_1_ (va_is_src_operand_uint64 src va_s0) /\ (va_get_ok
    va_s0)))
  (ensures (fun ((va_sM:va_state)) -> ((va_ensure va_b0 va_s0 va_sM va_sN) /\ (va_get_ok va_sM) /\
    (va_eval_dst_operand_uint64 va_sM dst) == (logxor64 (va_eval_dst_operand_uint64 va_s0 dst)
    (va_eval_operand_uint64 va_s0 src)) /\ (va_state_eq va_sM (va_update_flags va_sM (va_update_ok
    va_sM (va_update_dst_operand dst va_sM va_s0)))))))

assume val va_code_And64 : dst:va_dst_operand -> src:va_operand -> Tot va_code

assume val va_lemma_And64 : va_b0:va_codes -> va_s0:va_state -> va_sN:va_state ->
  dst:va_dst_operand -> src:va_operand
  -> Ghost ((va_sM:va_state))
  (requires (phase_1_ (va_require va_b0 (va_code_And64 dst src) va_s0 va_sN) /\
    phase_1_ (va_is_dst_dst_operand_uint64 dst va_s0) /\ phase_1_ (va_is_src_operand_uint64 src va_s0) /\ (va_get_ok
    va_s0)))
  (ensures (fun ((va_sM:va_state)) -> ((va_ensure va_b0 va_s0 va_sM va_sN) /\ (va_get_ok va_sM) /\
    (va_eval_dst_operand_uint64 va_sM dst) == (logand64 (va_eval_dst_operand_uint64 va_s0 dst)
    (va_eval_operand_uint64 va_s0 src)) /\ (va_state_eq va_sM (va_update_flags va_sM (va_update_ok
    va_sM (va_update_dst_operand dst va_sM va_s0)))))))

assume val va_code_Shl64 : dst:va_dst_operand -> amt:va_shift_amt -> Tot va_code

assume val va_lemma_Shl64 : va_b0:va_codes -> va_s0:va_state -> va_sN:va_state ->
  dst:va_dst_operand -> amt:va_shift_amt
  -> Ghost ((va_sM:va_state))
  (requires (phase_1_ (va_require va_b0 (va_code_Shl64 dst amt) va_s0 va_sN) /\
    phase_1_ (va_is_dst_dst_operand_uint64 dst va_s0) /\ phase_1_ (va_is_src_shift_amt_uint64 amt va_s0) /\
    (va_get_ok va_s0)))
  (ensures (fun ((va_sM:va_state)) -> ((va_ensure va_b0 va_s0 va_sM va_sN) /\ (va_get_ok va_sM) /\
    (va_eval_dst_operand_uint64 va_sM dst) == (shift_left64 (va_eval_dst_operand_uint64 va_s0 dst)
    (va_eval_shift_amt_uint64 va_s0 amt)) /\ (va_state_eq va_sM (va_update_flags va_sM
    (va_update_ok va_sM (va_update_dst_operand dst va_sM va_s0)))))))

assume val va_code_Shr64 : dst:va_dst_operand -> amt:va_shift_amt -> Tot va_code

assume val va_lemma_Shr64 : va_b0:va_codes -> va_s0:va_state -> va_sN:va_state ->
  dst:va_dst_operand -> amt:va_shift_amt
  -> Ghost ((va_sM:va_state))
  (requires (phase_1_ (va_require va_b0 (va_code_Shr64 dst amt) va_s0 va_sN) /\
    phase_1_ (va_is_dst_dst_operand_uint64 dst va_s0) /\ phase_1_ (va_is_src_shift_amt_uint64 amt va_s0) /\
    (va_get_ok va_s0)))
  (ensures (fun ((va_sM:va_state)) -> ((va_ensure va_b0 va_s0 va_sM va_sN) /\ (va_get_ok va_sM) /\
    (va_eval_dst_operand_uint64 va_sM dst) == (shift_right64 (va_eval_dst_operand_uint64 va_s0 dst)
    (va_eval_shift_amt_uint64 va_s0 amt)) /\ (va_state_eq va_sM (va_update_flags va_sM
    (va_update_ok va_sM (va_update_dst_operand dst va_sM va_s0)))))))
#endverbatim
